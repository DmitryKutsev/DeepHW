{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled45.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNEr0turB3uqAAxdatDjIHT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/DeepHW/blob/master/my_hw3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRpKt9HQ_Cxm",
        "outputId": "83aae41a-b3d5-4e4b-a17c-d0bb9f695f92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install youtokentome"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting youtokentome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/4a86cf99da3f680497ae132329025b291e2fda22327e8da6a9476e51acb1/youtokentome-1.0.6-cp36-cp36m-manylinux2010_x86_64.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from youtokentome) (7.1.2)\n",
            "Installing collected packages: youtokentome\n",
            "Successfully installed youtokentome-1.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "572tpApQ_XZR"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import random\n",
        "import json\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchtext\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "import math\n",
        "import youtokentome as yttm\n",
        "from torchtext.data import BucketIterator"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCZuiIVa_bLu"
      },
      "source": [
        "device = torch.device('cuda:0')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_whu949p0oz",
        "outputId": "4a20d8d9-246e-40df-dcf8-b17a9343a2fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA0HPUBq_eVc",
        "outputId": "85be45b5-bfc3-469a-8fb0-8a8c1ab550a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3ly4yuT_nQU",
        "outputId": "f35c2024-ddfe-4f4e-90a6-9b960fece249",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip '/content/drive/My Drive/unsupervised.csv.zip' "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/unsupervised.csv.zip\n",
            "  inflating: unsupervised.csv        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS8amS4NFQZx",
        "outputId": "2b27e5f2-da91-47e2-f64f-2e962c2d4b24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip '/content/drive/My Drive/qa_data.jsonl.zip'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/qa_data.jsonl.zip\n",
            "  inflating: qa_data.jsonl           \n",
            "  inflating: __MACOSX/._qa_data.jsonl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCeNvtFZHPQu"
      },
      "source": [
        "qa_data = list()\n",
        "\n",
        "with open('qa_data.jsonl') as file_object:\n",
        "    for line in file_object:\n",
        "        qa_data.append(json.loads(line.strip()))\n",
        "file_object.close()\n",
        "qa_data = qa_data[:math.ceil(len(qa_data)*0.4)]#!!!!"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS1ix4Qg98SF"
      },
      "source": [
        "train_border = math.ceil(len(qa_data)*0.6)\n",
        "test_border = math.ceil(len(qa_data)*0.8)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI7dMWOlFijS"
      },
      "source": [
        "train_df = pd.DataFrame(qa_data[:train_border])\n",
        "test_df = pd.DataFrame(qa_data[train_border:test_border])\n",
        "validation_df = pd.DataFrame(qa_data[test_border: ])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnRIP7Jb6bWf",
        "outputId": "8010b9ab-b737-4cf7-c4fe-dee6bf1f0595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "train_df"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>category</th>\n",
              "      <th>responses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>долго ли идут деньги с яндексденег на карту visa?</td>\n",
              "      <td>Бизнес, Финансы</td>\n",
              "      <td>[нет. прорыв 35 ;)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>можно ли зарегистрировать авто в другом регионе</td>\n",
              "      <td>Авто, Мото</td>\n",
              "      <td>[можно на родственника из того региона.. .  а ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>что делать если у меня очень тонкие ногти а хо...</td>\n",
              "      <td>Красота и Здоровье</td>\n",
              "      <td>[витамины и умная эмаль (каждый день), ванночк...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>в чем отличие медитации от йоги?</td>\n",
              "      <td>Спорт</td>\n",
              "      <td>[букв в йоге меньше, в медитации ты просто сид...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>когда начнут линейку фильмов про лигу чемпионов?</td>\n",
              "      <td>Спорт</td>\n",
              "      <td>[а не фильм? жалко... а я то думал - хорошая к...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674110</th>\n",
              "      <td>могут ли в 15 лет взять работать санитаркой в ...</td>\n",
              "      <td>Красота и Здоровье</td>\n",
              "      <td>[могут на неполный рабочий день., да . с работ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674111</th>\n",
              "      <td>можно сократить беременость симки?</td>\n",
              "      <td>Семья, Дом, Дети</td>\n",
              "      <td>[никак. там она и так короткая. 3дня, ахахахах...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674112</th>\n",
              "      <td>в каком случае нужно обязательно менять работу?</td>\n",
              "      <td>Работа, Карьера</td>\n",
              "      <td>[когда деваться некуда..., кода босс сильно да...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674113</th>\n",
              "      <td>вы часто сами себя накручиваете на ровном мест...</td>\n",
              "      <td>Знакомства, Любовь, Отношения</td>\n",
              "      <td>[если меня нет рядом, значит мыссленно и душой...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674114</th>\n",
              "      <td>друзья! подскажите какой-нибудь фильмец интере...</td>\n",
              "      <td>Искусство и Культура</td>\n",
              "      <td>[звёздная пыль  фокус-покус, ученик чародея, в...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>674115 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 question  ...                                          responses\n",
              "0       долго ли идут деньги с яндексденег на карту visa?  ...                                [нет. прорыв 35 ;)]\n",
              "1         можно ли зарегистрировать авто в другом регионе  ...  [можно на родственника из того региона.. .  а ...\n",
              "2       что делать если у меня очень тонкие ногти а хо...  ...  [витамины и умная эмаль (каждый день), ванночк...\n",
              "3                        в чем отличие медитации от йоги?  ...  [букв в йоге меньше, в медитации ты просто сид...\n",
              "4        когда начнут линейку фильмов про лигу чемпионов?  ...  [а не фильм? жалко... а я то думал - хорошая к...\n",
              "...                                                   ...  ...                                                ...\n",
              "674110  могут ли в 15 лет взять работать санитаркой в ...  ...  [могут на неполный рабочий день., да . с работ...\n",
              "674111                 можно сократить беременость симки?  ...  [никак. там она и так короткая. 3дня, ахахахах...\n",
              "674112    в каком случае нужно обязательно менять работу?  ...  [когда деваться некуда..., кода босс сильно да...\n",
              "674113  вы часто сами себя накручиваете на ровном мест...  ...  [если меня нет рядом, значит мыссленно и душой...\n",
              "674114  друзья! подскажите какой-нибудь фильмец интере...  ...  [звёздная пыль  фокус-покус, ученик чародея, в...\n",
              "\n",
              "[674115 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4nSrJ1SV-rY"
      },
      "source": [
        "validation_df[\"str_responses\"] = [\" \".join(i) for i in validation_df[\"responses\"]]\n",
        "train_df[\"str_responses\"] = [\" \".join(i) for i in train_df[\"responses\"]]\n",
        "test_df[\"str_responses\"] = [\" \".join(i) for i in test_df[\"responses\"]]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT7tr0Mz_ANf"
      },
      "source": [
        "train_df.to_csv(r'train.csv', index = False)\n",
        "test_df.to_csv(r'test.csv', index = False)\n",
        "validation_df.to_csv(r'validation.csv', index = False)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS_h0ZK0h5Bf"
      },
      "source": [
        "# my_train, my_test = train_test_split(my_df, test_size=0.2)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJu0jQu2NDIV"
      },
      "source": [
        "with open('for_bpe.txt', 'w', encoding='utf-8') as f:\n",
        "    for que in train_df['question']:\n",
        "        f.write(que + '\\n')\n",
        "f.close()\n",
        "\n",
        "vocab_size = 30_000\n",
        "model_path = 'pretrained_bpe_lm.model'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtHIJd3U_yz2",
        "outputId": "a037530e-1fc6-4fd0-c8d8-cecb7334e445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "# обучаем\n",
        "# раскомментируйте этот код, чтобы обучить bpe\n",
        "yttm.BPE.train(data='for_bpe.txt', vocab_size=vocab_size, model=model_path)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.62 s, sys: 1.02 s, total: 8.65 s\n",
            "Wall time: 5.4 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<youtokentome.youtokentome.BPE at 0x7f2a7bfa9f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBrHi-PQNyH5"
      },
      "source": [
        "tokenizer = yttm.BPE(model=model_path)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHfh54km_1ZT"
      },
      "source": [
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i70iHSLVBDeC",
        "outputId": "07bc2fef-f265-404d-f44b-8fcc8ff26ff4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# tokenized = []\n",
        "\n",
        "# batch_size = 256\n",
        "\n",
        "# for i_batch in tqdm(range(math.ceil(len(train_df['question']) / batch_size))):\n",
        "    \n",
        "#     tokenized.extend(tokenizer.encode(\n",
        "#         list(train_df['question'][i_batch*batch_size:(i_batch+1)*batch_size]), bos=True, eos=True))\n",
        "#     tokenized.extend(tokenizer.encode(\n",
        "#         list(train_df['str_responses'][i_batch*batch_size:(i_batch+1)*batch_size]), bos=True, eos=True))\n",
        "    # tokenized.extend(tokenizer.encode(\n",
        "    # list(my_df['str_responses'][i_batch*batch_size:(i_batch+1)*batch_size]), bos=True, eos=False))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2634/2634 [00:23<00:00, 110.34it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6I-o404MDm_"
      },
      "source": [
        "from torchtext import data, datasets"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clmYAh4AbA1J"
      },
      "source": [
        "def tokenize_question(text):\n",
        "  return tokenizer.encode(text, bos=True, eos=True, output_type=yttm.OutputType.SUBWORD)[::-1]\n",
        "\n",
        "def tokenize_answer(text):\n",
        "  return tokenizer.encode(text, bos=True, eos=True, output_type=yttm.OutputType.SUBWORD)#[::-1]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8U2LoMLWnQq"
      },
      "source": [
        "SRC = torchtext.data.Field(\n",
        "    tokenize = tokenize_question,\n",
        "    init_token = '<bos>',\n",
        "    eos_token = '<eos>',\n",
        "    lower= True,\n",
        "    include_lengths = True\n",
        ")\n",
        "\n",
        "TRG = torchtext.data.Field(\n",
        "    tokenize = tokenize_answer,\n",
        "    init_token = '<bos>',\n",
        "    eos_token = '<eos>',\n",
        "    lower= True,\n",
        "    include_lengths = True\n",
        ")\n",
        "\n",
        "fields = {\n",
        "    'question': ('src', SRC),\n",
        "    'str_responses': ('trg', TRG)\n",
        "}"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L14HDQlCLZSh"
      },
      "source": [
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "    path = '.',\n",
        "    train = 'train.csv',\n",
        "    test = 'test.csv',\n",
        "    validation = 'validation.csv',\n",
        "    format = 'csv',\n",
        "    fields = fields\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpgLiLE3pa1i"
      },
      "source": [
        "SRC.build_vocab([train_data.src, valid_data.src, test_data.src], max_size=25000, min_freq=3 )\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS0ResthqC8Y",
        "outputId": "c81debb8-a164-4965-ec75-4483058f4dcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "SRC.vocab.freqs.most_common(5)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<eos>', 1123522),\n",
              " ('<bos>', 1123522),\n",
              " ('▁в', 304922),\n",
              " ('▁на', 203104),\n",
              " ('▁как', 194327)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1wyCw3hpa-9",
        "outputId": "e3733e6a-93e7-4e6a-a93a-b57d97167236",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "TRG.build_vocab([train_data.src, valid_data.src, test_data.src],  min_freq=5)\n",
        "print(len(TRG.vocab))\n",
        "len(SRC.vocab)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smzs5QD1q50l"
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "              (train_data, valid_data, test_data),\n",
        "              batch_size = BATCH_SIZE,\n",
        "              sort_within_batch = True,\n",
        "              sort_key = lambda x : len(x.src),\n",
        "              device = device,\n",
        "          )"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEV__iclrWc6"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "    super().__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.emb_dim = emb_dim\n",
        "    self.enc_hid_dim = enc_hid_dim\n",
        "    self.dropout = dropout\n",
        "\n",
        "    self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "    self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "    self.fc = nn.Linear(enc_hid_dim*2, dec_hid_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "  def forward(self, src, src_len):\n",
        "    embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n",
        "\n",
        "    packed_outputs, hidden = self.rnn(packed_embedded)\n",
        "\n",
        "    outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
        "    hidden = torch.tanh(self.fc(torch.cat(hidden[-2,:,:], hidden[-1.:,:], dim = 1)))\n",
        "    return outputs, hidden\n",
        "    "
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tjXYKH1rWgS"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "    super().__init__()\n",
        "    self.enc_hid_dim = enc_hid_dim\n",
        "    self.dec_hid_dim = dec_hid_dim\n",
        "    self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "    self.v = nn.Parameter(torch.rand(dec_hid_dim))\n",
        "\n",
        "  def forward(self, hidden, encoder_outputs, mask):\n",
        "\n",
        "    bach_size = encoder_outputs.shape[1]\n",
        "    src_len = encoder_outputs.shape[0]\n",
        "    hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "    encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "    energy = energy.permute(0, 2, 1)\n",
        "    v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
        "\n",
        "    attention = torch.bmm(v, energy).squeeze(1)\n",
        "    attention = attention.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "    return F.softmax(attention, dim = 1)\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fSVcq6QrWaT"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "  def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.emb_dim = emb_dim\n",
        "    self.enc_hid_dim = enc_hid_dim\n",
        "    self.dec_hid_dim = dec_hid_dim\n",
        "    self.dropout = dropout\n",
        "    self.attention = attention\n",
        "\n",
        "    self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "    self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "    self.out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, input, hidden, encoder_outputs, mask):\n",
        "\n",
        "    input = input.unsqueeze(0)\n",
        "    embedded = self.dropout(self.embedding(input))\n",
        "    a = self.attention(hidden, encoder_outputs, mask)\n",
        "\n",
        "    a = a.unsqueeze(1)\n",
        "    encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "    weighted = torch.bmm(a, encoder_outputs)\n",
        "    weighted = weighted.per,ute(1, 0, 2)\n",
        "    rnn_input = torch.cat((embedded, weigthed), dim = 2)\n",
        "    output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "\n",
        "    assert (output == hidden).all()\n",
        "\n",
        "\n",
        "    embedded = embedded.squeeze(0)\n",
        "    output = output.squeeze(0)\n",
        "    weighted = weighted.squeeze(0)\n",
        "    output = self.out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "\n",
        "    \n",
        "    return output, hiden.squeeze(0), a.squeeze91\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O1safD63sDk"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder, pad_idx, sos_idx, eos_idx, device):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.pad_idx = pad_idx\n",
        "    self.sos_idx = sos_idx\n",
        "    self.eos_idx = eos_idx\n",
        "    self.device = device\n",
        "\n",
        "  def create_mask(self, src):\n",
        "    mask = (src != self.pad_idx).permute(1, 0)\n",
        "    return mask\n",
        "  \n",
        "  def forward(self, src, src_len, trg, teacher_forcing_ratio=0.5):\n",
        "    if trg is None:\n",
        "      assert teacher_forcing_ratio == 0\n",
        "      inference = Truetrg = torch.zeros((100, src.shape[1])).long().fill_(self.sos_idx).to(src.device)\n",
        "    else:\n",
        "      inference = False\n",
        "    \n",
        "    batch_size = src.shape[1]\n",
        "    max_len = trg,shape[0]\n",
        "    trg_vocab_size = delf.decoder.output_dim\n",
        "\n",
        "    outputs = torch.zeros(max_len, batch-size, trg_vocab_size).to(self.device)\n",
        "\n",
        "    attentions = torch.zeros(max_len, batch_size, src.shape[0]).to(self.device)\n",
        "\n",
        "    encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "\n",
        "    output = trg[0, :]\n",
        "    mask = self.create_mask(src)\n",
        "\n",
        "    for t in range(1, max_len):\n",
        "      output, hidden, attention = self.decoder(output, hidden, encoder_outputs, mask)\n",
        "      outputs[t] = outputattentions[t] = attentionteacher_force = random.random() < teacher_forcing_ratio\n",
        "      top1 = output.max(1)[1]\n",
        "      output = (trg[t] if teacher_force else top1)\n",
        "      if inference and output.item() == self.eos_idx:\n",
        "        return outputs[:t], attentions[:t]\n",
        "\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S35T2HwS-YkK",
        "outputId": "49346ecc-5373-4bc7-fc06-aa943bc2d62b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(SRC.vocab)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN8uNzrNrWXp"
      },
      "source": [
        "attn = Attention(100, 100)\n",
        "inp_dim = len(SRC.vocab)\n",
        "out_dim = len(TRG.vocab)\n",
        "\n",
        "enc = Encoder(inp_dim, 256, 100, 100, 0.8)\n",
        "dec = Decoder(out_dim, 256, 100, 100, 0.8, attention=attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC.vocab.stoi['<pad>'], TRG.vocab.stoi['<sos>'], TRG.vocab.stoi['<eos>'], device).to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WqBLUbCrWVJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMx0N0OKrrcf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlDtKcrhrrkc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA6XXiS3rriF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t8zjXzprrgI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzfZdF3Wijew"
      },
      "source": [
        "class LanguageModelData(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, data, max_len, pad_index, eos_index, bos_index):\n",
        "        \n",
        "        self.data = data\n",
        "        \n",
        "        self.max_len = max_len\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "        \n",
        "        # self.pad_index = pad_index\n",
        "        # self.bos_index = bos_index\n",
        "        # self.eos_index = eos_index\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        sequence = self.data[::2][:self.max_len]\n",
        "        \n",
        "        # исходная последовательность\n",
        "        x = sequence['question'][:self.max_len]\n",
        "        # нужно предсказать смещенную последовательность\n",
        "        y = sequence['str_responses'][:self.max_len]\n",
        "\n",
        "        \n",
        "        pads_x = [self.pad_index] * (self.max_len - len(x))\n",
        "        pads_y = [self.pad_index] * (self.max_len - len(y))\n",
        "        \n",
        "        x = torch.tensor(x + pads_x).long()\n",
        "        y = torch.tensor(y + pads_y).long()\n",
        "        \n",
        "        return x, y"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S1tEOuvnnoA",
        "outputId": "b4c39ce9-bc8f-443d-ceba-80c582b856d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lengths = np.array([len(x) for x in tokenized])\n",
        "np.percentile(lengths, q=95)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-OXLENtntnC",
        "outputId": "f8497812-5a5f-4cd4-c7ae-270198a90315",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer.vocab()[:15]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<PAD>',\n",
              " '<UNK>',\n",
              " '<BOS>',\n",
              " '<EOS>',\n",
              " '▁',\n",
              " 'о',\n",
              " 'а',\n",
              " 'е',\n",
              " 'т',\n",
              " 'и',\n",
              " 'н',\n",
              " 'с',\n",
              " 'к',\n",
              " 'р',\n",
              " 'в']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ViGWX5_nwyf"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "max_len = 32\n",
        "bos_index = 2\n",
        "pad_index = 0\n",
        "eos_index = 3"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74FfZfuCn7Q1"
      },
      "source": [
        "random.shuffle(tokenized)\n",
        "\n",
        "validation_start_index = int(len(tokenized) * 0.05)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppSUnhaTn7rV",
        "outputId": "bb73cb9c-1ae9-4e3d-95c6-bf849ca59d4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dataset = LanguageModelData(data=tokenized[:-validation_start_index], max_len=max_len, \n",
        "                                  pad_index=pad_index, eos_index=eos_index, bos_index=bos_index)\n",
        "validation_dataset = LanguageModelData(data=tokenized[-validation_start_index:], max_len=max_len,\n",
        "                                       pad_index=pad_index, eos_index=eos_index, bos_index=bos_index)\n",
        "\n",
        "len(train_dataset), len(validation_dataset)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3202046, 168528)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJAyLF0hcVdO",
        "outputId": "1c6110ed-a782-41f1-b0c7-b47c51255a69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer.encode('как сделать эту адову домаш 15', bos=True, eos=True, output_type=yttm.OutputType.SUBWORD)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<BOS>',\n",
              " '▁как',\n",
              " '▁сделать',\n",
              " '▁эту',\n",
              " '▁а',\n",
              " 'до',\n",
              " 'ву',\n",
              " '▁домаш',\n",
              " '▁15',\n",
              " '<EOS>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoaF9285oDMX"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITit4QWApLOr"
      },
      "source": [
        "\n",
        "class LanguageModel(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embedding_dim, model_dim, num_layers, dropout, padding_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        # просто эмбеддинги\n",
        "        self.embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size, \n",
        "                                                  embedding_dim=embedding_dim,\n",
        "                                                  padding_idx=padding_idx)\n",
        "        \n",
        "        # просто lstm\n",
        "        self.lstm = torch.nn.LSTM(input_size=embedding_dim, \n",
        "                                  hidden_size=model_dim,\n",
        "                                  num_layers=num_layers, \n",
        "                                  dropout=0.3,\n",
        "                                  batch_first=True)\n",
        "        \n",
        "        # выходная матрица эмбеддингов\n",
        "        # количество выходных фичей равно размеру словаря\n",
        "        # то есть это задача мультиклассовой классификации, но только классов очень много\n",
        "        self.language_model_head = torch.nn.Linear(in_features=model_dim,\n",
        "                                                   out_features=vocab_size,\n",
        "                                                   bias=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.embedding_layer(x)\n",
        "        \n",
        "        x, _ = self.lstm(x)\n",
        "        \n",
        "        # к каждому элементу последовательности применяется выходная матрица эмбеддингов, \n",
        "        # которая переводит вектор lstm в предсказание конкретного слова\n",
        "        x = self.language_model_head(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-o8nonkpdao"
      },
      "source": [
        "embedding_dim = 128\n",
        "model_dim = 128\n",
        "num_layers = 2\n",
        "dropout = 0.35"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yw6p2bDpk8i",
        "outputId": "95dbd993-f2cb-4934-85b7-f0dfe50156f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = LanguageModel(vocab_size=vocab_size, embedding_dim=embedding_dim,\n",
        "                      model_dim=model_dim, num_layers=num_layers,\n",
        "                      dropout=dropout, padding_idx=pad_index)\n",
        "model.to(device)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding_layer): Embedding(30000, 128, padding_idx=0)\n",
              "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.3)\n",
              "  (language_model_head): Linear(in_features=128, out_features=30000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CYRtSd0pnoj"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCmRd5HFus4V",
        "outputId": "ad5e93c1-bbe6-46fd-d77a-6a993e13a0ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "print(f'Количество обучаемых параметров в сети: {count_parameters(model):,}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество обучаемых параметров в сети: 7,944,192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxDSGlCQuwT5"
      },
      "source": [
        "x = x.to(device)\n",
        "y = y.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTYpOcsru46X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}