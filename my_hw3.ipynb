{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled44.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPX9rKOXX/nEmy4WolqF+1S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/DeepHW/blob/master/my_hw3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2CFSkzkOu4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0994332f-88f5-4d7b-d2c2-97b6f6069f75"
      },
      "source": [
        "!pip install youtokentome"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: youtokentome in /usr/local/lib/python3.6/dist-packages (1.0.6)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from youtokentome) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwqHJV1-Epko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15855acd-3f2f-4891-abfd-28f461f0f78e"
      },
      "source": [
        "!pip install alive-progress"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: alive-progress in /usr/local/lib/python3.6/dist-packages (1.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rg43AAFBh7e"
      },
      "source": [
        "# !wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "# !dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "# !apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "# !apt-get update\n",
        "# !apt-get install cuda"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIA1x7RzBq9D"
      },
      "source": [
        "# !pip install mxnet-cu92"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmrVqnzMMxMr"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "import random\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import youtokentome as yttm"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WsCrjTDDG0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d02b6fc8-e40c-4c43-cb64-010556332e3c"
      },
      "source": [
        "print(torch.cuda.device_count())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQkrv7tBDa1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c3cafbc-72ee-4de1-e741-c5890a7fc6dd"
      },
      "source": [
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla P4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbq8KBUcDsMc"
      },
      "source": [
        "device = torch.device('cuda:0')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB1OFN7RB-8w"
      },
      "source": [
        "# !pip install --upgrade --force-reinstall -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQsaa759SujQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5907ac84-8ea8-4adf-ffce-3e0b6e9ae498"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsUhzBGgT8R-"
      },
      "source": [
        "# !unzip '/content/drive/My Drive/unsupervised.csv.zip'"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqzqdz21Vh39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a408277-b4bd-48d7-a9c9-0798ac12649f"
      },
      "source": [
        "!unzip '/content/drive/My Drive/qa_data.jsonl.zip'"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/qa_data.jsonl.zip\n",
            "replace qa_data.jsonl? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpw5KDsGOrTT"
      },
      "source": [
        "# questions = pd.read_csv('unsupervised.csv')\n",
        "# questions.question = questions.question.map(lambda x: x.lower())\n",
        "\n",
        "qa_data = list()\n",
        "\n",
        "with open('qa_data.jsonl') as file_object:\n",
        "    for line in file_object:\n",
        "        qa_data.append(json.loads(line.strip()))\n",
        "file_object.close()\n",
        "qa_data = qa_data[:math.ceil(len(qa_data)*0.4)]#!!!!"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns8YADUtVxQT"
      },
      "source": [
        "with open('for_bpe.txt', 'w', encoding='utf-8') as f:\n",
        "    for que in qa_data:\n",
        "        f.write(que['question'] + '\\n')\n",
        "f.close()\n",
        "\n",
        "vocab_size = 30_000\n",
        "model_path = 'pretrained_bpe_lm.model'"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy6lmKpjW8ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863a3d64-c475-4ec4-8d8c-4a608afe5749"
      },
      "source": [
        "%%time\n",
        "# обучаем\n",
        "# раскомментируйте этот код, чтобы обучить bpe\n",
        "yttm.BPE.train(data='for_bpe.txt', vocab_size=vocab_size, model=model_path)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.94 s, sys: 909 ms, total: 10.8 s\n",
            "Wall time: 6.63 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<youtokentome.youtokentome.BPE at 0x7f225673f518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Pyz-GbXmEQ"
      },
      "source": [
        "# загружаем токенизатор\n",
        "tokenizer = yttm.BPE(model=model_path)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQPHpsjkSXEW"
      },
      "source": [
        "qa_data = qa_data[:math.ceil(len(qa_data)*0.6)]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXhx2QIskXuy"
      },
      "source": [
        "my_pairs = []\n",
        "max_length = 32\n",
        "for i in qa_data:\n",
        "  quest = i['question']\n",
        "  for resp in i['responses']:\n",
        "    pair = (quest, resp)\n",
        "    # pair.append(tok_quest, tokenizer.encode(resp, bos=True, eos=True))\n",
        "    my_pairs.append(pair)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBIho8jAixIJ"
      },
      "source": [
        "# tok_pairs = []\n",
        "# max_length = 32\n",
        "# for i in qa_data:\n",
        "  \n",
        "#   tok_quest = tokenizer.encode(i['question'], eos=True)\n",
        "#   for resp in i['responses']:\n",
        "#     pair = (tok_quest, tokenizer.encode(resp, eos=True))\n",
        "#     # pair.append(tok_quest, tokenizer.encode(resp, bos=True, eos=True))\n",
        "#     tok_pairs.append(pair)\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjrqaxTfmtXh"
      },
      "source": [
        "import pandas as pd "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfb2Vx3-S1-y"
      },
      "source": [
        "my_frame = pd.DataFrame(my_pairs)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJBfciqqm06f",
        "outputId": "a1502c85-9eb6-4902-bc45-b0d85e48068b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "my_frame.columns = ['q', 'ans']\n",
        "my_frame = my_frame[:4000]\n",
        "my_frame"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q</th>\n",
              "      <th>ans</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>долго ли идут деньги с яндексденег на карту visa?</td>\n",
              "      <td>нет. прорыв 35 ;)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>можно ли зарегистрировать авто в другом регионе</td>\n",
              "      <td>можно на родственника из того региона.. .  а п...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>что делать если у меня очень тонкие ногти а хо...</td>\n",
              "      <td>витамины и умная эмаль (каждый день)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>что делать если у меня очень тонкие ногти а хо...</td>\n",
              "      <td>ванночки с морской солью. с вечера мажь ногти ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>что делать если у меня очень тонкие ногти а хо...</td>\n",
              "      <td>умная эмаль, витамины, йод, и поменьше крась л...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>моя дочь хочет в художественную гимнастику ей ...</td>\n",
              "      <td>нет! поздно! отдайте в бальные танцы.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>какие лучше купить витамины для 17-летней дево...</td>\n",
              "      <td>витамины фирм \"амвей\", \"арго\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>какие лучше купить витамины для 17-летней дево...</td>\n",
              "      <td>алфавит - ничего лучше раздельного приёма ещё ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>что вы хотели бы забыть ?</td>\n",
              "      <td>забыть что старость приближаетца</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>что вы хотели бы забыть ?</td>\n",
              "      <td>уже и не вспомнить-забыла!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      q                                                ans\n",
              "0     долго ли идут деньги с яндексденег на карту visa?                                  нет. прорыв 35 ;)\n",
              "1       можно ли зарегистрировать авто в другом регионе  можно на родственника из того региона.. .  а п...\n",
              "2     что делать если у меня очень тонкие ногти а хо...               витамины и умная эмаль (каждый день)\n",
              "3     что делать если у меня очень тонкие ногти а хо...  ванночки с морской солью. с вечера мажь ногти ...\n",
              "4     что делать если у меня очень тонкие ногти а хо...  умная эмаль, витамины, йод, и поменьше крась л...\n",
              "...                                                 ...                                                ...\n",
              "3995  моя дочь хочет в художественную гимнастику ей ...              нет! поздно! отдайте в бальные танцы.\n",
              "3996  какие лучше купить витамины для 17-летней дево...                      витамины фирм \"амвей\", \"арго\"\n",
              "3997  какие лучше купить витамины для 17-летней дево...  алфавит - ничего лучше раздельного приёма ещё ...\n",
              "3998                          что вы хотели бы забыть ?                   забыть что старость приближаетца\n",
              "3999                          что вы хотели бы забыть ?                         уже и не вспомнить-забыла!\n",
              "\n",
              "[4000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFIY-yxBqbGV"
      },
      "source": [
        "my_frame.to_csv('my_frame.csv', index=False)  "
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbf6oJflrWb_"
      },
      "source": [
        "max_length = 20\n",
        "def tokenize(text):\n",
        "  return tokenizer.encode(text, output_type=yttm.OutputType.SUBWORD)[:max_length]"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmbfDDVVrSm1"
      },
      "source": [
        "SRC = Field(tokenize=tokenize, init_token='<sos>', eos_token='<eos>')\n",
        "TRG = Field(tokenize=tokenize, init_token='<sos>', eos_token='<eos>')"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT2ykmymVttb"
      },
      "source": [
        "dataset = TabularDataset(path='my_frame.csv', \n",
        "                         format='csv', \n",
        "                         fields=[ ('ans', TRG), ('q', SRC),],\n",
        "                         skip_header=True)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSwG260UB8Rl"
      },
      "source": [
        "train_data, valid_data, test_data = dataset.split(split_ratio=[0.7, 0.1, 0.2], \n",
        "                                            random_state=random.getstate())"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaB8jxb-VtwO"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq=2)\n",
        "TRG.build_vocab(train_data, min_freq=2)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcHhlLMVVxVv",
        "outputId": "2f6d75c7-f5e4-440a-ac5e-fb4ba55c67fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(vars(train_data.examples[0])['ans'])"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁как', '▁уговорить', '▁родителей', '▁купить', '▁мопе', 'д?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cmk19Bzs-Zx"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort_key=lambda x: len(x.ans), \n",
        "     sort_within_batch=False,\n",
        "     device = device)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt5XNNdwtbl6",
        "outputId": "80089df5-61cc-41bb-8a54-b82e3210dc85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (len(SRC.vocab), len(TRG.vocab))\n",
        "print (SRC.vocab.freqs.most_common(10))\n",
        "print (TRG.vocab.freqs.most_common(10))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4087 4662\n",
            "[('▁не', 763), ('▁и', 724), ('▁в', 564), ('.', 515), ('▁а', 390), ('▁на', 365), (',', 269), ('!', 269), ('▁что', 267), ('▁это', 255)]\n",
            "[('▁в', 647), ('▁как', 499), ('▁на', 495), ('▁что', 401), ('▁и', 401), ('▁не', 367), ('▁а', 362), ('▁с', 324), ('▁вы', 305), ('▁ли', 233)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL94XxhXtdow"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))        \n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "        \n",
        "        return hidden, cell"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv8BdRtQtiGp"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))        \n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "        \n",
        "        return hidden, cell"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e1n2Z9otwEH"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, cell):\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "                \n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        \n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        \n",
        "        return prediction, hidden, cell"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2l4LU5pty_E"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        hidden, cell = self.encoder(src)\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            outputs[t] = output\n",
        "            \n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1) \n",
        "            input = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diF5dCzat10E"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.6\n",
        "DEC_DROPOUT = 0.6\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVaBWC_rt4yw",
        "outputId": "3f12e184-833a-4fab-89c8-cf665fe223ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(4087, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.6)\n",
              "    (dropout): Dropout(p=0.6, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(4662, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.6)\n",
              "    (fc_out): Linear(in_features=512, out_features=4662, bias=True)\n",
              "    (dropout): Dropout(p=0.6, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axUHBGGLt8Gp",
        "outputId": "466b2925-d628-483b-b96d-c6847a785638",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 11,987,766 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5wcy8OCt-m9",
        "outputId": "72eb3c9b-3200-490b-d418-70f2d717e31f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "pad_idx = TRG.vocab.stoi['<pad>']\n",
        "print(TRG.pad_token)  \n",
        "print(TRG.vocab.stoi[TRG.pad_token]) \n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<pad>\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eckir9S6uA8f"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    my_losses = []\n",
        "    for i, batch in enumerate(iterator):\n",
        "        # progress_bar = tqdm(total=len(iterator), desc=f'{ i }')\n",
        "        src = batch.q\n",
        "        trg = batch.ans\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        my_losses.append(loss.item())\n",
        "        if i%10 == 0:\n",
        "          print(f'fmean losses: { np.mean(my_losses[-1000:]) } ', f'iter { i }' )\n",
        "        # progress_bar.set_postfix(loss=np.mean(my_losses[-1000:]),\n",
        "                            # perplexity=np.exp(np.mean(my_losses[-1000:])))\n",
        "        # progress_bar.update()\n",
        "     # progress_bar.close()\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kawMJSULutrA"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.q\n",
        "            trg = batch.ans\n",
        "\n",
        "            output = model(src, trg, 0) \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMQ1hz-JuwR2"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9cKoYAkuyY-"
      },
      "source": [
        "import time"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwcq6WHguz_e",
        "outputId": "e1676fc6-5a61-45aa-9363-70dc3d4a1e59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 1\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    # valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    # if valid_loss < best_valid_loss:\n",
        "    #     best_valid_loss = valid_loss\n",
        "    #     torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fmean losses: 8.465895652770996  iter 0\n",
            "fmean losses: 7.713003548708829  iter 10\n",
            "Epoch: 01 | Time: 0m 2s\n",
            "\tTrain Loss: 7.713 | Train PPL: 2237.252\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMzc6bIKu2fK"
      },
      "source": [
        "def translate_sentence(sentence,src_field,trg_field,model,device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    if isinstance(sentence,str):\n",
        "        tokens = tokenizer.encode(sentence, output_type=yttm.OutputType.SUBWORD)\n",
        "    else:\n",
        "        tokens = tokenizer.encode(sentence, output_type=yttm.OutputType.SUBWORD)\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    #\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token)\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "\n",
        "    return trg_tokens[1:-1] # remove <sos> and <eos>"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDDQhgimvqrs",
        "outputId": "bd6e84fc-6813-4895-efb5-3c2afc010c11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "example_idx = 24\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['q']\n",
        "src = \" \".join(src)\n",
        "trg = vars(train_data.examples[example_idx])['ans']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "\n",
        "translation = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ▁бро сь ▁его, ▁пока ▁не ▁поздно ! ▁его ▁не ▁передела ешь !!!\n",
            "trg = ['▁как', '▁нужно', '▁поступить', '▁с', '▁мужчиной,', '▁который', '▁претен', 'дует', '▁на', '▁твоё', '▁личное', '▁простран', 'ство', '▁дик', 'ту', 'я', '▁свои', '▁условия?', ')))']\n",
            "predicted trg = ['▁как', '▁в', '▁в']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qv-z-3Hvsza",
        "outputId": "3d369ed2-bca9-4505-f488-86e3eed04f6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "translation = translate_sentence('что делать', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "\n",
        "translation = translate_sentence('зачем мне это все?', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "\n",
        "translation = translate_sentence('это не нормально, памагити', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "\n",
        "translation = translate_sentence('зачем?', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "\n",
        "translation = translate_sentence('что делать, если холодно', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['▁как', '<unk>']\n",
            "predicted trg = ['▁как', '▁в']\n",
            "predicted trg = ['▁как', '▁в']\n",
            "predicted trg = ['<unk>', '<unk>']\n",
            "predicted trg = ['▁как', '<unk>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G962o6pAwBSJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}