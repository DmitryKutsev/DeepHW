{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMv9SNEjegrzxZNc8matnKX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/DeepHW/blob/master/Untitled78.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IerJlxzNg4Wo",
        "outputId": "14324389-d246-4dfb-f620-4bd338a13a34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gspread gspread_dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN6KaWX5rrCs",
        "outputId": "875d2f02-454b-4ad2-8784-69b8a4553c0e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.0)\n",
            "Requirement already satisfied: gspread_dataframe in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from gspread_dataframe) (2.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread_dataframe) (1.17.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2025.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "jx7wsDT0hSOb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gspread\n",
        "from gspread_dataframe import get_as_dataframe\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "9LFIQE9srv7n"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_url = '/reddit-cleanjokes-reddit-cleanjokes.csv'\n",
        "df = pd.read_csv(data_url, sep=',')"
      ],
      "metadata": {
        "id": "m4pH49rbsEQI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xNIizsm5r0Z0",
        "outputId": "9edb28f8-8da4-4806-8a0f-05b9d8145bd5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID                                               Joke\n",
              "0   1  What did the bartender say to the jumper cable...\n",
              "1   2  Don't you hate jokes about German sausage? The...\n",
              "2   3  Two artists had an art contest... It ended in ...\n",
              "3   4  Why did the chicken cross the playground? To g...\n",
              "4   5   What gun do you use to hunt a moose? A moosecut!"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-161484d2-9c4a-4f2b-b1dc-8e1c815eab58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Joke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>What did the bartender say to the jumper cable...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Don't you hate jokes about German sausage? The...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Two artists had an art contest... It ended in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Why did the chicken cross the playground? To g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>What gun do you use to hunt a moose? A moosecut!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-161484d2-9c4a-4f2b-b1dc-8e1c815eab58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-161484d2-9c4a-4f2b-b1dc-8e1c815eab58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-161484d2-9c4a-4f2b-b1dc-8e1c815eab58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cb61b9d5-1df2-40ab-a7b6-44cc7f390a05\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb61b9d5-1df2-40ab-a7b6-44cc7f390a05')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cb61b9d5-1df2-40ab-a7b6-44cc7f390a05 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1622,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 468,\n        \"min\": 1,\n        \"max\": 1622,\n        \"num_unique_values\": 1622,\n        \"samples\": [\n          136,\n          845,\n          835\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Joke\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1611,\n        \"samples\": [\n          \"Why do gorillas have such big nostrils? Cos they got big fingers.\",\n          \"What was Marie Curie's fitness program on the airwaves called? Radio-Activity\",\n          \"What did the grape say when it got stepped on? Nothing, it just gave a little wine\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        sequence_length = 4,\n",
        "        data_url = '123',\n",
        "    ):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.data_url = data_url\n",
        "\n",
        "        self.words = self.load_words()\n",
        "        self.unique_words = self.get_unique_words()\n",
        "\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.unique_words)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.unique_words)}\n",
        "\n",
        "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "\n",
        "    def load_words(self):\n",
        "        train_df = pd.read_csv(self.data_url)\n",
        "        text = train_df['Joke'].str.cat(sep=' ')\n",
        "        return text.split(' ')\n",
        "\n",
        "    def get_unique_words(self):\n",
        "        word_counts = Counter(self.words)\n",
        "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words_indexes) - self.sequence_length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
        "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
        "        )"
      ],
      "metadata": {
        "id": "cvq3Oww0hvd_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset(data_url=data_url)"
      ],
      "metadata": {
        "id": "jFjAEx040uTZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.__getitem__(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67qwuN7k2WjZ",
        "outputId": "0169f30d-688d-4642-87b0-ba589e6f42a8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  8,   0, 248,  20]), tensor([  0, 248,  20,   4]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch, (x, y) in enumerate(data):\n",
        "  print(batch, \"batch\")\n",
        "  print(x, \"x\")\n",
        "  print(y, \"y\")\n",
        "\n",
        "  if batch == 3:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwIgrrD4x15d",
        "outputId": "5dca0749-19cc-4ec3-bf78-e68bd7bd92e0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 batch\n",
            "tensor([  2,   8,   0, 248]) x\n",
            "tensor([  8,   0, 248,  20]) y\n",
            "1 batch\n",
            "tensor([  8,   0, 248,  20]) x\n",
            "tensor([  0, 248,  20,   4]) y\n",
            "2 batch\n",
            "tensor([  0, 248,  20,   4]) x\n",
            "tensor([248,  20,   4,   0]) y\n",
            "3 batch\n",
            "tensor([248,  20,   4,   0]) x\n",
            "tensor([  20,    4,    0, 1905]) y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, dataset, lstm_size = 128, embedding_dim = 128, num_layers = 3):\n",
        "        super(Model, self).__init__()\n",
        "        self.lstm_size = lstm_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_layers = num_layers\n",
        "        n_vocab = len(dataset.unique_words)\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.embedding_dim,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.2,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
        "\n",
        "    def forward(self, x, state):\n",
        "      embedding = self.embedding(x)\n",
        "      output, new_state = self.lstm(embedding, state)\n",
        "      y = self.fc(output)\n",
        "      return y, new_state\n",
        "\n",
        "    def init_state(self, batch_size):\n",
        "      return (torch.zeros(self.num_layers, batch_size, self.lstm_size),\n",
        "                torch.zeros(self.num_layers, batch_size, self.lstm_size))"
      ],
      "metadata": {
        "id": "gXwPJmN8rsQQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, loss_fn_int, train_dataloader, test_dataloader,\n",
        "          device, epochs = 10, batch_size = 16):\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    state_c, state_h = model.init_state(batch_size)\n",
        "    state_h = state_h.to(device)\n",
        "    state_c = state_c.to(device)\n",
        "\n",
        "    for batch, (x, y) in enumerate(train_dataloader):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "      state_h = state_h.detach()\n",
        "      state_c = state_c.detach()\n",
        "\n",
        "      loss = loss_fn_int(y_pred.transpose(1, 2), y)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if batch % 100 == 0:\n",
        "          print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })"
      ],
      "metadata": {
        "id": "ps3f7kQqxW-L"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "epochs = 20\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "dataset = data\n",
        "model = Model(dataset = dataset).to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "train_dataloader = DataLoader(dataset, batch_size=batch_size, drop_last=True)\n",
        "test_dataloader = DataLoader(dataset, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "\n",
        "train(model, optimizer, loss, train_dataloader, test_dataloader, device, epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "TCGuF9JHxYep",
        "outputId": "cad03494-21e1-4e34-8960-274382b92e06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 0, 'batch': 0, 'loss': 8.836273193359375}\n",
            "{'epoch': 0, 'batch': 100, 'loss': 7.62273645401001}\n",
            "{'epoch': 0, 'batch': 200, 'loss': 7.228198051452637}\n",
            "{'epoch': 0, 'batch': 300, 'loss': 7.604579448699951}\n",
            "{'epoch': 0, 'batch': 400, 'loss': 7.4838175773620605}\n",
            "{'epoch': 0, 'batch': 500, 'loss': 7.012760639190674}\n",
            "{'epoch': 0, 'batch': 600, 'loss': 7.205508232116699}\n",
            "{'epoch': 0, 'batch': 700, 'loss': 7.754366874694824}\n",
            "{'epoch': 0, 'batch': 800, 'loss': 8.026273727416992}\n",
            "{'epoch': 0, 'batch': 900, 'loss': 6.481708526611328}\n",
            "{'epoch': 0, 'batch': 1000, 'loss': 7.287766456604004}\n",
            "{'epoch': 0, 'batch': 1100, 'loss': 7.1055145263671875}\n",
            "{'epoch': 0, 'batch': 1200, 'loss': 6.407154083251953}\n",
            "{'epoch': 0, 'batch': 1300, 'loss': 8.612984657287598}\n",
            "{'epoch': 0, 'batch': 1400, 'loss': 6.116302967071533}\n",
            "{'epoch': 1, 'batch': 0, 'loss': 6.938194274902344}\n",
            "{'epoch': 1, 'batch': 100, 'loss': 6.381833553314209}\n",
            "{'epoch': 1, 'batch': 200, 'loss': 6.163071155548096}\n",
            "{'epoch': 1, 'batch': 300, 'loss': 6.472741603851318}\n",
            "{'epoch': 1, 'batch': 400, 'loss': 6.413454055786133}\n",
            "{'epoch': 1, 'batch': 500, 'loss': 6.322364330291748}\n",
            "{'epoch': 1, 'batch': 600, 'loss': 6.20705509185791}\n",
            "{'epoch': 1, 'batch': 700, 'loss': 7.191318511962891}\n",
            "{'epoch': 1, 'batch': 800, 'loss': 6.714062213897705}\n",
            "{'epoch': 1, 'batch': 900, 'loss': 5.480951309204102}\n",
            "{'epoch': 1, 'batch': 1000, 'loss': 6.489863395690918}\n",
            "{'epoch': 1, 'batch': 1100, 'loss': 6.0248703956604}\n",
            "{'epoch': 1, 'batch': 1200, 'loss': 5.724535942077637}\n",
            "{'epoch': 1, 'batch': 1300, 'loss': 7.671470642089844}\n",
            "{'epoch': 1, 'batch': 1400, 'loss': 5.500356197357178}\n",
            "{'epoch': 2, 'batch': 0, 'loss': 6.321874618530273}\n",
            "{'epoch': 2, 'batch': 100, 'loss': 6.0554680824279785}\n",
            "{'epoch': 2, 'batch': 200, 'loss': 5.979704856872559}\n",
            "{'epoch': 2, 'batch': 300, 'loss': 6.061773300170898}\n",
            "{'epoch': 2, 'batch': 400, 'loss': 5.980254173278809}\n",
            "{'epoch': 2, 'batch': 500, 'loss': 5.857529640197754}\n",
            "{'epoch': 2, 'batch': 600, 'loss': 5.7307891845703125}\n",
            "{'epoch': 2, 'batch': 700, 'loss': 6.720005512237549}\n",
            "{'epoch': 2, 'batch': 800, 'loss': 5.981555461883545}\n",
            "{'epoch': 2, 'batch': 900, 'loss': 4.932545185089111}\n",
            "{'epoch': 2, 'batch': 1000, 'loss': 5.869720458984375}\n",
            "{'epoch': 2, 'batch': 1100, 'loss': 5.092695236206055}\n",
            "{'epoch': 2, 'batch': 1200, 'loss': 5.07096004486084}\n",
            "{'epoch': 2, 'batch': 1300, 'loss': 7.002963066101074}\n",
            "{'epoch': 2, 'batch': 1400, 'loss': 5.021042823791504}\n",
            "{'epoch': 3, 'batch': 0, 'loss': 5.838345527648926}\n",
            "{'epoch': 3, 'batch': 100, 'loss': 5.585380554199219}\n",
            "{'epoch': 3, 'batch': 200, 'loss': 5.74457311630249}\n",
            "{'epoch': 3, 'batch': 300, 'loss': 5.644924640655518}\n",
            "{'epoch': 3, 'batch': 400, 'loss': 5.682252407073975}\n",
            "{'epoch': 3, 'batch': 500, 'loss': 5.292878150939941}\n",
            "{'epoch': 3, 'batch': 600, 'loss': 5.200902938842773}\n",
            "{'epoch': 3, 'batch': 700, 'loss': 6.232888698577881}\n",
            "{'epoch': 3, 'batch': 800, 'loss': 5.452596664428711}\n",
            "{'epoch': 3, 'batch': 900, 'loss': 4.552048683166504}\n",
            "{'epoch': 3, 'batch': 1000, 'loss': 5.478947639465332}\n",
            "{'epoch': 3, 'batch': 1100, 'loss': 4.512823581695557}\n",
            "{'epoch': 3, 'batch': 1200, 'loss': 4.610227108001709}\n",
            "{'epoch': 3, 'batch': 1300, 'loss': 6.570896625518799}\n",
            "{'epoch': 3, 'batch': 1400, 'loss': 4.665454864501953}\n",
            "{'epoch': 4, 'batch': 0, 'loss': 5.572012424468994}\n",
            "{'epoch': 4, 'batch': 100, 'loss': 5.36989164352417}\n",
            "{'epoch': 4, 'batch': 200, 'loss': 5.3629279136657715}\n",
            "{'epoch': 4, 'batch': 300, 'loss': 5.190803527832031}\n",
            "{'epoch': 4, 'batch': 400, 'loss': 5.184116840362549}\n",
            "{'epoch': 4, 'batch': 500, 'loss': 4.79227876663208}\n",
            "{'epoch': 4, 'batch': 600, 'loss': 4.921750545501709}\n",
            "{'epoch': 4, 'batch': 700, 'loss': 5.781038284301758}\n",
            "{'epoch': 4, 'batch': 800, 'loss': 5.135346412658691}\n",
            "{'epoch': 4, 'batch': 900, 'loss': 4.235225200653076}\n",
            "{'epoch': 4, 'batch': 1000, 'loss': 5.030269145965576}\n",
            "{'epoch': 4, 'batch': 1100, 'loss': 4.19590950012207}\n",
            "{'epoch': 4, 'batch': 1200, 'loss': 4.2040863037109375}\n",
            "{'epoch': 4, 'batch': 1300, 'loss': 6.510094165802002}\n",
            "{'epoch': 4, 'batch': 1400, 'loss': 4.169487476348877}\n",
            "{'epoch': 5, 'batch': 0, 'loss': 5.250783443450928}\n",
            "{'epoch': 5, 'batch': 100, 'loss': 4.894985675811768}\n",
            "{'epoch': 5, 'batch': 200, 'loss': 5.216411590576172}\n",
            "{'epoch': 5, 'batch': 300, 'loss': 4.933024883270264}\n",
            "{'epoch': 5, 'batch': 400, 'loss': 5.215003967285156}\n",
            "{'epoch': 5, 'batch': 500, 'loss': 4.322082996368408}\n",
            "{'epoch': 5, 'batch': 600, 'loss': 4.563382148742676}\n",
            "{'epoch': 5, 'batch': 700, 'loss': 5.4765238761901855}\n",
            "{'epoch': 5, 'batch': 800, 'loss': 4.68536376953125}\n",
            "{'epoch': 5, 'batch': 900, 'loss': 3.8430399894714355}\n",
            "{'epoch': 5, 'batch': 1000, 'loss': 4.865192413330078}\n",
            "{'epoch': 5, 'batch': 1100, 'loss': 4.200478553771973}\n",
            "{'epoch': 5, 'batch': 1200, 'loss': 3.973344564437866}\n",
            "{'epoch': 5, 'batch': 1300, 'loss': 5.775458812713623}\n",
            "{'epoch': 5, 'batch': 1400, 'loss': 4.008928298950195}\n",
            "{'epoch': 6, 'batch': 0, 'loss': 4.919704437255859}\n",
            "{'epoch': 6, 'batch': 100, 'loss': 4.75419807434082}\n",
            "{'epoch': 6, 'batch': 200, 'loss': 5.129952907562256}\n",
            "{'epoch': 6, 'batch': 300, 'loss': 4.554047107696533}\n",
            "{'epoch': 6, 'batch': 400, 'loss': 5.1482648849487305}\n",
            "{'epoch': 6, 'batch': 500, 'loss': 4.1703691482543945}\n",
            "{'epoch': 6, 'batch': 600, 'loss': 4.292821407318115}\n",
            "{'epoch': 6, 'batch': 700, 'loss': 5.225116729736328}\n",
            "{'epoch': 6, 'batch': 800, 'loss': 4.454746246337891}\n",
            "{'epoch': 6, 'batch': 900, 'loss': 3.7177257537841797}\n",
            "{'epoch': 6, 'batch': 1000, 'loss': 4.786224365234375}\n",
            "{'epoch': 6, 'batch': 1100, 'loss': 3.9314022064208984}\n",
            "{'epoch': 6, 'batch': 1200, 'loss': 3.8046326637268066}\n",
            "{'epoch': 6, 'batch': 1300, 'loss': 5.398109436035156}\n",
            "{'epoch': 6, 'batch': 1400, 'loss': 3.709956645965576}\n",
            "{'epoch': 7, 'batch': 0, 'loss': 4.566850185394287}\n",
            "{'epoch': 7, 'batch': 100, 'loss': 4.645721912384033}\n",
            "{'epoch': 7, 'batch': 200, 'loss': 4.890671730041504}\n",
            "{'epoch': 7, 'batch': 300, 'loss': 4.35651969909668}\n",
            "{'epoch': 7, 'batch': 400, 'loss': 4.7705302238464355}\n",
            "{'epoch': 7, 'batch': 500, 'loss': 3.932647705078125}\n",
            "{'epoch': 7, 'batch': 600, 'loss': 3.877885103225708}\n",
            "{'epoch': 7, 'batch': 700, 'loss': 4.7583489418029785}\n",
            "{'epoch': 7, 'batch': 800, 'loss': 4.182369232177734}\n",
            "{'epoch': 7, 'batch': 900, 'loss': 3.3940908908843994}\n",
            "{'epoch': 7, 'batch': 1000, 'loss': 4.527911186218262}\n",
            "{'epoch': 7, 'batch': 1100, 'loss': 3.6863293647766113}\n",
            "{'epoch': 7, 'batch': 1200, 'loss': 3.3172006607055664}\n",
            "{'epoch': 7, 'batch': 1300, 'loss': 5.0024003982543945}\n",
            "{'epoch': 7, 'batch': 1400, 'loss': 3.5289039611816406}\n",
            "{'epoch': 8, 'batch': 0, 'loss': 4.404006004333496}\n",
            "{'epoch': 8, 'batch': 100, 'loss': 4.451908588409424}\n",
            "{'epoch': 8, 'batch': 200, 'loss': 4.669764041900635}\n",
            "{'epoch': 8, 'batch': 300, 'loss': 4.118118762969971}\n",
            "{'epoch': 8, 'batch': 400, 'loss': 4.534058570861816}\n",
            "{'epoch': 8, 'batch': 500, 'loss': 3.816340208053589}\n",
            "{'epoch': 8, 'batch': 600, 'loss': 3.506795644760132}\n",
            "{'epoch': 8, 'batch': 700, 'loss': 4.305698871612549}\n",
            "{'epoch': 8, 'batch': 800, 'loss': 4.033638954162598}\n",
            "{'epoch': 8, 'batch': 900, 'loss': 3.2481980323791504}\n",
            "{'epoch': 8, 'batch': 1000, 'loss': 4.24329948425293}\n",
            "{'epoch': 8, 'batch': 1100, 'loss': 3.212841510772705}\n",
            "{'epoch': 8, 'batch': 1200, 'loss': 3.1455211639404297}\n",
            "{'epoch': 8, 'batch': 1300, 'loss': 4.644906520843506}\n",
            "{'epoch': 8, 'batch': 1400, 'loss': 3.217846632003784}\n",
            "{'epoch': 9, 'batch': 0, 'loss': 4.179892063140869}\n",
            "{'epoch': 9, 'batch': 100, 'loss': 4.125532627105713}\n",
            "{'epoch': 9, 'batch': 200, 'loss': 4.444286346435547}\n",
            "{'epoch': 9, 'batch': 300, 'loss': 3.981719493865967}\n",
            "{'epoch': 9, 'batch': 400, 'loss': 4.357213020324707}\n",
            "{'epoch': 9, 'batch': 500, 'loss': 3.6672592163085938}\n",
            "{'epoch': 9, 'batch': 600, 'loss': 3.339367151260376}\n",
            "{'epoch': 9, 'batch': 700, 'loss': 4.075388431549072}\n",
            "{'epoch': 9, 'batch': 800, 'loss': 3.698503017425537}\n",
            "{'epoch': 9, 'batch': 900, 'loss': 2.9817657470703125}\n",
            "{'epoch': 9, 'batch': 1000, 'loss': 3.967883586883545}\n",
            "{'epoch': 9, 'batch': 1100, 'loss': 3.1361348628997803}\n",
            "{'epoch': 9, 'batch': 1200, 'loss': 3.0411272048950195}\n",
            "{'epoch': 9, 'batch': 1300, 'loss': 4.357132911682129}\n",
            "{'epoch': 9, 'batch': 1400, 'loss': 3.216735601425171}\n",
            "{'epoch': 10, 'batch': 0, 'loss': 3.8402762413024902}\n",
            "{'epoch': 10, 'batch': 100, 'loss': 4.046690940856934}\n",
            "{'epoch': 10, 'batch': 200, 'loss': 4.3180389404296875}\n",
            "{'epoch': 10, 'batch': 300, 'loss': 3.934854507446289}\n",
            "{'epoch': 10, 'batch': 400, 'loss': 4.095792770385742}\n",
            "{'epoch': 10, 'batch': 500, 'loss': 3.5623233318328857}\n",
            "{'epoch': 10, 'batch': 600, 'loss': 3.150800943374634}\n",
            "{'epoch': 10, 'batch': 700, 'loss': 3.762002468109131}\n",
            "{'epoch': 10, 'batch': 800, 'loss': 3.7498936653137207}\n",
            "{'epoch': 10, 'batch': 900, 'loss': 2.7756402492523193}\n",
            "{'epoch': 10, 'batch': 1000, 'loss': 3.8722596168518066}\n",
            "{'epoch': 10, 'batch': 1100, 'loss': 2.975688934326172}\n",
            "{'epoch': 10, 'batch': 1200, 'loss': 2.937046766281128}\n",
            "{'epoch': 10, 'batch': 1300, 'loss': 4.065747261047363}\n",
            "{'epoch': 10, 'batch': 1400, 'loss': 2.8908634185791016}\n",
            "{'epoch': 11, 'batch': 0, 'loss': 3.646108865737915}\n",
            "{'epoch': 11, 'batch': 100, 'loss': 3.817781925201416}\n",
            "{'epoch': 11, 'batch': 200, 'loss': 3.940075159072876}\n",
            "{'epoch': 11, 'batch': 300, 'loss': 3.7303574085235596}\n",
            "{'epoch': 11, 'batch': 400, 'loss': 3.7569541931152344}\n",
            "{'epoch': 11, 'batch': 500, 'loss': 3.337606430053711}\n",
            "{'epoch': 11, 'batch': 600, 'loss': 3.1125519275665283}\n",
            "{'epoch': 11, 'batch': 700, 'loss': 3.4613728523254395}\n",
            "{'epoch': 11, 'batch': 800, 'loss': 3.376368284225464}\n",
            "{'epoch': 11, 'batch': 900, 'loss': 2.1890227794647217}\n",
            "{'epoch': 11, 'batch': 1000, 'loss': 3.734388828277588}\n",
            "{'epoch': 11, 'batch': 1100, 'loss': 2.8642630577087402}\n",
            "{'epoch': 11, 'batch': 1200, 'loss': 2.4435110092163086}\n",
            "{'epoch': 11, 'batch': 1300, 'loss': 3.7348546981811523}\n",
            "{'epoch': 11, 'batch': 1400, 'loss': 2.8370158672332764}\n",
            "{'epoch': 12, 'batch': 0, 'loss': 3.5683045387268066}\n",
            "{'epoch': 12, 'batch': 100, 'loss': 3.4127132892608643}\n",
            "{'epoch': 12, 'batch': 200, 'loss': 4.142282485961914}\n",
            "{'epoch': 12, 'batch': 300, 'loss': 3.3078622817993164}\n",
            "{'epoch': 12, 'batch': 400, 'loss': 3.7081804275512695}\n",
            "{'epoch': 12, 'batch': 500, 'loss': 3.3070068359375}\n",
            "{'epoch': 12, 'batch': 600, 'loss': 2.922131061553955}\n",
            "{'epoch': 12, 'batch': 700, 'loss': 3.245678424835205}\n",
            "{'epoch': 12, 'batch': 800, 'loss': 3.309436082839966}\n",
            "{'epoch': 12, 'batch': 900, 'loss': 2.059884786605835}\n",
            "{'epoch': 12, 'batch': 1000, 'loss': 3.505699396133423}\n",
            "{'epoch': 12, 'batch': 1100, 'loss': 2.6497082710266113}\n",
            "{'epoch': 12, 'batch': 1200, 'loss': 2.3210935592651367}\n",
            "{'epoch': 12, 'batch': 1300, 'loss': 3.6836917400360107}\n",
            "{'epoch': 12, 'batch': 1400, 'loss': 2.8672680854797363}\n",
            "{'epoch': 13, 'batch': 0, 'loss': 3.265864372253418}\n",
            "{'epoch': 13, 'batch': 100, 'loss': 3.396963596343994}\n",
            "{'epoch': 13, 'batch': 200, 'loss': 3.7017035484313965}\n",
            "{'epoch': 13, 'batch': 300, 'loss': 3.173182964324951}\n",
            "{'epoch': 13, 'batch': 400, 'loss': 3.386291980743408}\n",
            "{'epoch': 13, 'batch': 500, 'loss': 3.029533624649048}\n",
            "{'epoch': 13, 'batch': 600, 'loss': 2.9223122596740723}\n",
            "{'epoch': 13, 'batch': 700, 'loss': 3.05814266204834}\n",
            "{'epoch': 13, 'batch': 800, 'loss': 3.4043569564819336}\n",
            "{'epoch': 13, 'batch': 900, 'loss': 2.086845874786377}\n",
            "{'epoch': 13, 'batch': 1000, 'loss': 3.5138745307922363}\n",
            "{'epoch': 13, 'batch': 1100, 'loss': 2.6782050132751465}\n",
            "{'epoch': 13, 'batch': 1200, 'loss': 2.3896408081054688}\n",
            "{'epoch': 13, 'batch': 1300, 'loss': 3.605799436569214}\n",
            "{'epoch': 13, 'batch': 1400, 'loss': 2.9485280513763428}\n",
            "{'epoch': 14, 'batch': 0, 'loss': 3.1307153701782227}\n",
            "{'epoch': 14, 'batch': 100, 'loss': 3.2205536365509033}\n",
            "{'epoch': 14, 'batch': 200, 'loss': 3.367305040359497}\n",
            "{'epoch': 14, 'batch': 300, 'loss': 2.8750576972961426}\n",
            "{'epoch': 14, 'batch': 400, 'loss': 3.1797237396240234}\n",
            "{'epoch': 14, 'batch': 500, 'loss': 3.036633253097534}\n",
            "{'epoch': 14, 'batch': 600, 'loss': 2.699503183364868}\n",
            "{'epoch': 14, 'batch': 700, 'loss': 2.8403258323669434}\n",
            "{'epoch': 14, 'batch': 800, 'loss': 3.205258846282959}\n",
            "{'epoch': 14, 'batch': 900, 'loss': 1.9646239280700684}\n",
            "{'epoch': 14, 'batch': 1000, 'loss': 3.3866119384765625}\n",
            "{'epoch': 14, 'batch': 1100, 'loss': 2.40470027923584}\n",
            "{'epoch': 14, 'batch': 1200, 'loss': 2.2758772373199463}\n",
            "{'epoch': 14, 'batch': 1300, 'loss': 3.11135196685791}\n",
            "{'epoch': 14, 'batch': 1400, 'loss': 2.605468273162842}\n",
            "{'epoch': 15, 'batch': 0, 'loss': 2.95833420753479}\n",
            "{'epoch': 15, 'batch': 100, 'loss': 3.166337728500366}\n",
            "{'epoch': 15, 'batch': 200, 'loss': 3.186873197555542}\n",
            "{'epoch': 15, 'batch': 300, 'loss': 2.859896183013916}\n",
            "{'epoch': 15, 'batch': 400, 'loss': 3.157637596130371}\n",
            "{'epoch': 15, 'batch': 500, 'loss': 3.0572376251220703}\n",
            "{'epoch': 15, 'batch': 600, 'loss': 2.5421648025512695}\n",
            "{'epoch': 15, 'batch': 700, 'loss': 2.47629714012146}\n",
            "{'epoch': 15, 'batch': 800, 'loss': 3.1528425216674805}\n",
            "{'epoch': 15, 'batch': 900, 'loss': 1.7335454225540161}\n",
            "{'epoch': 15, 'batch': 1000, 'loss': 3.319195032119751}\n",
            "{'epoch': 15, 'batch': 1100, 'loss': 2.454355239868164}\n",
            "{'epoch': 15, 'batch': 1200, 'loss': 2.1726300716400146}\n",
            "{'epoch': 15, 'batch': 1300, 'loss': 3.0285043716430664}\n",
            "{'epoch': 15, 'batch': 1400, 'loss': 2.441439151763916}\n",
            "{'epoch': 16, 'batch': 0, 'loss': 2.747753143310547}\n",
            "{'epoch': 16, 'batch': 100, 'loss': 2.8514370918273926}\n",
            "{'epoch': 16, 'batch': 200, 'loss': 2.961792469024658}\n",
            "{'epoch': 16, 'batch': 300, 'loss': 2.8586204051971436}\n",
            "{'epoch': 16, 'batch': 400, 'loss': 2.692734718322754}\n",
            "{'epoch': 16, 'batch': 500, 'loss': 2.93446946144104}\n",
            "{'epoch': 16, 'batch': 600, 'loss': 2.6241416931152344}\n",
            "{'epoch': 16, 'batch': 700, 'loss': 2.349975347518921}\n",
            "{'epoch': 16, 'batch': 800, 'loss': 2.851996898651123}\n",
            "{'epoch': 16, 'batch': 900, 'loss': 1.7688454389572144}\n",
            "{'epoch': 16, 'batch': 1000, 'loss': 3.039511203765869}\n",
            "{'epoch': 16, 'batch': 1100, 'loss': 2.17809796333313}\n",
            "{'epoch': 16, 'batch': 1200, 'loss': 2.1968212127685547}\n",
            "{'epoch': 16, 'batch': 1300, 'loss': 2.776519536972046}\n",
            "{'epoch': 16, 'batch': 1400, 'loss': 2.3184938430786133}\n",
            "{'epoch': 17, 'batch': 0, 'loss': 2.752896785736084}\n",
            "{'epoch': 17, 'batch': 100, 'loss': 2.907637596130371}\n",
            "{'epoch': 17, 'batch': 200, 'loss': 2.73725962638855}\n",
            "{'epoch': 17, 'batch': 300, 'loss': 2.5802857875823975}\n",
            "{'epoch': 17, 'batch': 400, 'loss': 2.6180174350738525}\n",
            "{'epoch': 17, 'batch': 500, 'loss': 2.723878860473633}\n",
            "{'epoch': 17, 'batch': 600, 'loss': 2.520806074142456}\n",
            "{'epoch': 17, 'batch': 700, 'loss': 2.5176284313201904}\n",
            "{'epoch': 17, 'batch': 800, 'loss': 2.9802048206329346}\n",
            "{'epoch': 17, 'batch': 900, 'loss': 1.6109602451324463}\n",
            "{'epoch': 17, 'batch': 1000, 'loss': 2.837289333343506}\n",
            "{'epoch': 17, 'batch': 1100, 'loss': 2.281536340713501}\n",
            "{'epoch': 17, 'batch': 1200, 'loss': 2.0095174312591553}\n",
            "{'epoch': 17, 'batch': 1300, 'loss': 2.5177907943725586}\n",
            "{'epoch': 17, 'batch': 1400, 'loss': 2.27347469329834}\n",
            "{'epoch': 18, 'batch': 0, 'loss': 2.6372108459472656}\n",
            "{'epoch': 18, 'batch': 100, 'loss': 2.598482370376587}\n",
            "{'epoch': 18, 'batch': 200, 'loss': 2.766700267791748}\n",
            "{'epoch': 18, 'batch': 300, 'loss': 2.4472575187683105}\n",
            "{'epoch': 18, 'batch': 400, 'loss': 2.777658462524414}\n",
            "{'epoch': 18, 'batch': 500, 'loss': 2.406613826751709}\n",
            "{'epoch': 18, 'batch': 600, 'loss': 2.4054386615753174}\n",
            "{'epoch': 18, 'batch': 700, 'loss': 2.256746530532837}\n",
            "{'epoch': 18, 'batch': 800, 'loss': 2.819241762161255}\n",
            "{'epoch': 18, 'batch': 900, 'loss': 1.5548467636108398}\n",
            "{'epoch': 18, 'batch': 1000, 'loss': 2.4600412845611572}\n",
            "{'epoch': 18, 'batch': 1100, 'loss': 2.034480571746826}\n",
            "{'epoch': 18, 'batch': 1200, 'loss': 1.9282110929489136}\n",
            "{'epoch': 18, 'batch': 1300, 'loss': 2.2191686630249023}\n",
            "{'epoch': 18, 'batch': 1400, 'loss': 2.15450119972229}\n",
            "{'epoch': 19, 'batch': 0, 'loss': 2.5513789653778076}\n",
            "{'epoch': 19, 'batch': 100, 'loss': 2.4929656982421875}\n",
            "{'epoch': 19, 'batch': 200, 'loss': 2.6519739627838135}\n",
            "{'epoch': 19, 'batch': 300, 'loss': 2.511434316635132}\n",
            "{'epoch': 19, 'batch': 400, 'loss': 2.544201135635376}\n",
            "{'epoch': 19, 'batch': 500, 'loss': 2.4211132526397705}\n",
            "{'epoch': 19, 'batch': 600, 'loss': 2.207927703857422}\n",
            "{'epoch': 19, 'batch': 700, 'loss': 1.7182984352111816}\n",
            "{'epoch': 19, 'batch': 800, 'loss': 2.6894314289093018}\n",
            "{'epoch': 19, 'batch': 900, 'loss': 1.566495656967163}\n",
            "{'epoch': 19, 'batch': 1000, 'loss': 2.572932720184326}\n",
            "{'epoch': 19, 'batch': 1100, 'loss': 2.038213014602661}\n",
            "{'epoch': 19, 'batch': 1200, 'loss': 1.8984112739562988}\n",
            "{'epoch': 19, 'batch': 1300, 'loss': 2.336308479309082}\n",
            "{'epoch': 19, 'batch': 1400, 'loss': 1.8608248233795166}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(dataset, model, text, next_words=10):\n",
        "    #your code here\n",
        "    words = text.split(' ')\n",
        "    state_h, state_c = model.init_state(1)\n",
        "    state_h = state_h.to(device)\n",
        "    state_c = state_c.to(device)\n",
        "    for w in words:\n",
        "      x = torch.tensor([[dataset.word_to_index[w]]]).to(device)\n",
        "      y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "      state_h = state_h.detach()\n",
        "      state_c = state_c.detach()\n",
        "\n",
        "    for i in range(0, next_words):\n",
        "      y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "      last_word_logits = y_pred[0][-1]\n",
        "      p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().cpu().numpy()\n",
        "      word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "      words.append(dataset.index_to_word[word_index])\n",
        "\n",
        "    return words\n"
      ],
      "metadata": {
        "id": "5rY1mcy_xafZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(dataset, model, text='Knock knock. Whos there?')"
      ],
      "metadata": {
        "id": "tL68a4VohIDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7083a7aa-6284-4a59-b3fe-a456a77ebbf1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Knock',\n",
              " 'knock.',\n",
              " 'Whos',\n",
              " 'there?',\n",
              " 'Ash',\n",
              " 'Well,',\n",
              " '\"Why',\n",
              " 'Day:',\n",
              " 'sly',\n",
              " 'Beer.',\n",
              " 'For',\n",
              " 'NO',\n",
              " 'NO',\n",
              " 'Well']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(dataset, model, text='Three man come into the bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcni-hJYbyhc",
        "outputId": "a234b92b-038f-4f4f-f5db-6711bcc864f0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Three',\n",
              " 'man',\n",
              " 'come',\n",
              " 'into',\n",
              " 'the',\n",
              " 'bar',\n",
              " '...but',\n",
              " '2.',\n",
              " 'It',\n",
              " 'Two',\n",
              " 'behind',\n",
              " 'in',\n",
              " 'who',\n",
              " 'was',\n",
              " 'it',\n",
              " '*Then']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tK7cl8gezWgs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}