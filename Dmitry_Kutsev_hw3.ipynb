{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled44.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOAcfY2+rK1HiQSV5mn5X3K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/DeepHW/blob/master/Dmitry_Kutsev_hw3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2CFSkzkOu4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1246912-a53e-420f-d1cb-acbbd0bf3f71"
      },
      "source": [
        "!pip install youtokentome"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting youtokentome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/4a86cf99da3f680497ae132329025b291e2fda22327e8da6a9476e51acb1/youtokentome-1.0.6-cp36-cp36m-manylinux2010_x86_64.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from youtokentome) (7.1.2)\n",
            "Installing collected packages: youtokentome\n",
            "Successfully installed youtokentome-1.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwqHJV1-Epko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3120cf-7abc-46b2-e037-6a062a7f46bb"
      },
      "source": [
        "!pip install alive-progress"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting alive-progress\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/46/25535783b6d88f7b85a71a4393f658baee5c5df5064c410e14058296a042/alive_progress-1.6.1-py3-none-any.whl\n",
            "Installing collected packages: alive-progress\n",
            "Successfully installed alive-progress-1.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmrVqnzMMxMr"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "import random\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import youtokentome as yttm"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WsCrjTDDG0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fbfbb2a-a843-4e39-8431-574b3422bb44"
      },
      "source": [
        "print(torch.cuda.device_count())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQkrv7tBDa1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "760e0392-1018-45f0-bbb6-05e60cb0f545"
      },
      "source": [
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQsaa759SujQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "409b4fce-368a-4446-9223-54afba8080bc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqzqdz21Vh39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f0c8ebb-5c3c-43ab-a201-d423dfbb6784"
      },
      "source": [
        "!unzip '/content/drive/My Drive/qa_data.jsonl.zip'"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/qa_data.jsonl.zip\n",
            "  inflating: qa_data.jsonl           \n",
            "  inflating: __MACOSX/._qa_data.jsonl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpw5KDsGOrTT"
      },
      "source": [
        "# questions = pd.read_csv('unsupervised.csv')\n",
        "# questions.question = questions.question.map(lambda x: x.lower())\n",
        "\n",
        "qa_data = list()\n",
        "\n",
        "with open('qa_data.jsonl') as file_object:\n",
        "    for line in file_object:\n",
        "        qa_data.append(json.loads(line.strip()))\n",
        "file_object.close()\n",
        "qa_data = qa_data[:math.ceil(len(qa_data)*0.4)]#!!!!"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns8YADUtVxQT"
      },
      "source": [
        "with open('for_bpe.txt', 'w', encoding='utf-8') as f:\n",
        "    for que in qa_data:\n",
        "        f.write(que['question'] + '\\n')\n",
        "f.close()\n",
        "\n",
        "vocab_size = 30_000\n",
        "model_path = 'pretrained_bpe_lm.model'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZvTSnd84uRR"
      },
      "source": [
        "Обучение и загрузка токенизатора\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy6lmKpjW8ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d004b22f-69ee-41e5-c578-913d802f66a6"
      },
      "source": [
        "\n",
        "%%time\n",
        "yttm.BPE.train(data='for_bpe.txt', vocab_size=vocab_size, model=model_path)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.1 s, sys: 1.18 s, total: 11.3 s\n",
            "Wall time: 7.01 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<youtokentome.youtokentome.BPE at 0x7f6ac7082cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Pyz-GbXmEQ"
      },
      "source": [
        "\n",
        "tokenizer = yttm.BPE(model=model_path)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQPHpsjkSXEW"
      },
      "source": [
        "qa_data = qa_data[:math.ceil(len(qa_data)*0.6)]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXhx2QIskXuy"
      },
      "source": [
        "my_pairs = []\n",
        "max_length = 32\n",
        "for i in qa_data:\n",
        "  quest = i['question']\n",
        "  for resp in i['responses']:\n",
        "    pair = (quest, resp)\n",
        "    # pair.append(tok_quest, tokenizer.encode(resp, bos=True, eos=True))\n",
        "    my_pairs.append(pair)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjrqaxTfmtXh"
      },
      "source": [
        "import pandas as pd "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfb2Vx3-S1-y"
      },
      "source": [
        "my_frame = pd.DataFrame(my_pairs)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWu61jbS42OD"
      },
      "source": [
        "Посмотреть данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJBfciqqm06f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "19024497-4d73-425b-aedb-f95892559d13"
      },
      "source": [
        "my_frame.columns = ['q', 'ans']\n",
        "my_frame = my_frame[:8000]\n",
        "my_frame"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q</th>\n",
              "      <th>ans</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>долго ли идут деньги с яндексденег на карту visa?</td>\n",
              "      <td>нет. прорыв 35 ;)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>можно ли зарегистрировать авто в другом регионе</td>\n",
              "      <td>можно на родственника из того региона.. .  а п...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>что делать если у меня очень тонкие ногти а хо...</td>\n",
              "      <td>витамины и умная эмаль (каждый день)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>что делать если у меня очень тонкие ногти а хо...</td>\n",
              "      <td>ванночки с морской солью. с вечера мажь ногти ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>что делать если у меня очень тонкие ногти а хо...</td>\n",
              "      <td>умная эмаль, витамины, йод, и поменьше крась л...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>куртка на зиму. какие куртки будут модно зимой:?</td>\n",
              "      <td>в стиле ретро, и каасуал!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>считаете ли вы себя мизантропом?</td>\n",
              "      <td>нет, мы здесь все филантропы. а? а? как вам та...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>почему богатым не прилично работать?</td>\n",
              "      <td>они работают ещё как или воруют это тоже работа</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>почему богатым не прилично работать?</td>\n",
              "      <td>кто тебе сказал - они работают, как правило ди...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>почему богатым не прилично работать?</td>\n",
              "      <td>неприлично работать ворам в законе, да еще нищ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      q                                                ans\n",
              "0     долго ли идут деньги с яндексденег на карту visa?                                  нет. прорыв 35 ;)\n",
              "1       можно ли зарегистрировать авто в другом регионе  можно на родственника из того региона.. .  а п...\n",
              "2     что делать если у меня очень тонкие ногти а хо...               витамины и умная эмаль (каждый день)\n",
              "3     что делать если у меня очень тонкие ногти а хо...  ванночки с морской солью. с вечера мажь ногти ...\n",
              "4     что делать если у меня очень тонкие ногти а хо...  умная эмаль, витамины, йод, и поменьше крась л...\n",
              "...                                                 ...                                                ...\n",
              "7995   куртка на зиму. какие куртки будут модно зимой:?                          в стиле ретро, и каасуал!\n",
              "7996                   считаете ли вы себя мизантропом?  нет, мы здесь все филантропы. а? а? как вам та...\n",
              "7997               почему богатым не прилично работать?    они работают ещё как или воруют это тоже работа\n",
              "7998               почему богатым не прилично работать?  кто тебе сказал - они работают, как правило ди...\n",
              "7999               почему богатым не прилично работать?  неприлично работать ворам в законе, да еще нищ...\n",
              "\n",
              "[8000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFIY-yxBqbGV"
      },
      "source": [
        "my_frame.to_csv('my_frame.csv', index=False)  "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNdxJvwb5BiL"
      },
      "source": [
        "Обработка/разбивка данных + итератор"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbf6oJflrWb_"
      },
      "source": [
        "max_length = 20\n",
        "def tokenize(text):\n",
        "  return tokenizer.encode(text, output_type=yttm.OutputType.SUBWORD)[:max_length]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmbfDDVVrSm1"
      },
      "source": [
        "SRC = Field(tokenize=tokenize, init_token='<sos>', eos_token='<eos>')\n",
        "TRG = Field(tokenize=tokenize, init_token='<sos>', eos_token='<eos>')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT2ykmymVttb"
      },
      "source": [
        "dataset = TabularDataset(path='my_frame.csv', \n",
        "                         format='csv', \n",
        "                         fields=[ ('ans', TRG), ('q', SRC),],\n",
        "                         skip_header=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSwG260UB8Rl"
      },
      "source": [
        "train_data, valid_data, test_data = dataset.split(split_ratio=[0.7, 0.1, 0.2], \n",
        "                                            random_state=random.getstate())"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaB8jxb-VtwO"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq=2)\n",
        "TRG.build_vocab(train_data, min_freq=2)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcHhlLMVVxVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3582b1d-fa7a-474c-f394-033c06b37f9e"
      },
      "source": [
        "print(vars(train_data.examples[0])['ans'])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁сегодня', '▁ночью', '▁шел', '▁пешком', '▁через', '▁весь', '▁город', '▁15', 'км.', '▁это', '▁нормально', '▁или', '▁нет?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cmk19Bzs-Zx"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort_key=lambda x: len(x.ans), \n",
        "     sort_within_batch=False,\n",
        "     device = device)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt5XNNdwtbl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3263e031-1678-4971-b319-07fda126cd90"
      },
      "source": [
        "print (len(SRC.vocab), len(TRG.vocab))\n",
        "print (SRC.vocab.freqs.most_common(10))\n",
        "print (TRG.vocab.freqs.most_common(10))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7291 7749\n",
            "[('▁не', 1471), ('▁и', 1445), ('▁в', 1133), ('.', 963), ('▁на', 739), ('▁а', 735), (',', 522), ('!', 513), ('▁с', 494), ('▁что', 493)]\n",
            "[('▁в', 1288), ('▁как', 969), ('▁на', 944), ('▁что', 924), ('▁и', 815), ('▁не', 721), ('▁вы', 632), ('▁а', 621), ('▁с', 578), ('▁у', 483)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHKA2MbY5Nin"
      },
      "source": [
        "Сама модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL94XxhXtdow"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor) -> Tuple[Tensor]:\n",
        "\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "\n",
        "        return outputs, hidden\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv8BdRtQtiGp"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 attn_dim: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "\n",
        "        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
        "\n",
        "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
        "\n",
        "    def forward(self,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((\n",
        "            repeated_decoder_hidden,\n",
        "            encoder_outputs),\n",
        "            dim = 2)))\n",
        "\n",
        "        attention = torch.sum(energy, dim=2)\n",
        "\n",
        "        return F.softmax(attention, dim=1)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e1n2Z9otwEH"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 output_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: int,\n",
        "                 attention: nn.Module):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "\n",
        "        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def _weighted_encoder_rep(self,\n",
        "                              decoder_hidden: Tensor,\n",
        "                              encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        a = self.attention(decoder_hidden, encoder_outputs)\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
        "\n",
        "        return weighted_encoder_rep\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "                input: Tensor,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tuple[Tensor]:\n",
        "\n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden,\n",
        "                                                          encoder_outputs)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
        "\n",
        "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
        "\n",
        "        output = self.out(torch.cat((output,\n",
        "                                     weighted_encoder_rep,\n",
        "                                     embedded), dim = 1))\n",
        "\n",
        "        return output, decoder_hidden.squeeze(0)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2l4LU5pty_E"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder: nn.Module,\n",
        "                 decoder: nn.Module,\n",
        "                 device: torch.device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                teacher_forcing_ratio: float = 0.5) -> Tensor:\n",
        "\n",
        "        batch_size = src.shape[1]\n",
        "        max_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "        output = trg[0,:]\n",
        "\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.max(1)[1]\n",
        "            output = (trg[t] if teacher_force else top1)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diF5dCzat10E"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "# ENC_EMB_DIM = 256\n",
        "# DEC_EMB_DIM = 256\n",
        "# HID_DIM = 512\n",
        "# N_LAYERS = 2\n",
        "# ENC_DROPOUT = 0.6\n",
        "# DEC_DROPOUT = 0.6\n",
        "\n",
        "\n",
        "# ENC_EMB_DIM = 256\n",
        "# DEC_EMB_DIM = 256\n",
        "# ENC_HID_DIM = 512\n",
        "# DEC_HID_DIM = 512\n",
        "# ATTN_DIM = 64\n",
        "# ENC_DROPOUT = 0.5\n",
        "# DEC_DROPOUT = 0.5\n",
        "\n",
        "ENC_EMB_DIM = 32\n",
        "DEC_EMB_DIM = 32\n",
        "ENC_HID_DIM = 64\n",
        "DEC_HID_DIM = 64\n",
        "ATTN_DIM = 8\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVaBWC_rt4yw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f59c11e4-b081-4f01-94cd-c704022562b3"
      },
      "source": [
        "def init_weights(m: nn.Module):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,315,629 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8wtVUIVQrnt"
      },
      "source": [
        "PAD_IDX = SRC.vocab.stoi['<pad>']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Usq2FNIT5cyh"
      },
      "source": [
        "Тренировочный и валидационный циклы.\n",
        "\n",
        "*Опять же из-за глюков в колабе не стал приделывать прогресс бар, вывод потерь просто в принте.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eckir9S6uA8f"
      },
      "source": [
        "def train(model: nn.Module,\n",
        "          iterator: torch.utils.data.DataLoader,\n",
        "          optimizer: optim.Optimizer,\n",
        "          criterion: nn.Module,\n",
        "          clip: float):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "\n",
        "        src = batch.q\n",
        "        trg = batch.ans\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kawMJSULutrA"
      },
      "source": [
        "def evaluate(model: nn.Module,\n",
        "             iterator: torch.utils.data.DataLoader,\n",
        "             criterion: nn.Module):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.q\n",
        "            trg = batch.ans\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMQ1hz-JuwR2"
      },
      "source": [
        " def epoch_time(start_time: int,\n",
        "               end_time: int):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "N_EPOCHS = 15\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9cKoYAkuyY-"
      },
      "source": [
        "import time"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFJX35c4Ri8Q",
        "outputId": "30cd7068-e65b-4e67-9287-2af189edb21b"
      },
      "source": [
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 4s\n",
            "\tTrain Loss: 8.836 | Train PPL: 6874.124\n",
            "\t Val. Loss: 8.124 |  Val. PPL: 3373.297\n",
            "Epoch: 02 | Time: 0m 4s\n",
            "\tTrain Loss: 7.649 | Train PPL: 2099.290\n",
            "\t Val. Loss: 7.041 |  Val. PPL: 1143.056\n",
            "Epoch: 03 | Time: 0m 4s\n",
            "\tTrain Loss: 7.382 | Train PPL: 1606.457\n",
            "\t Val. Loss: 6.986 |  Val. PPL: 1081.657\n",
            "Epoch: 04 | Time: 0m 4s\n",
            "\tTrain Loss: 7.346 | Train PPL: 1549.631\n",
            "\t Val. Loss: 6.949 |  Val. PPL: 1042.441\n",
            "Epoch: 05 | Time: 0m 4s\n",
            "\tTrain Loss: 7.327 | Train PPL: 1520.785\n",
            "\t Val. Loss: 6.939 |  Val. PPL: 1031.386\n",
            "Epoch: 06 | Time: 0m 4s\n",
            "\tTrain Loss: 7.304 | Train PPL: 1486.222\n",
            "\t Val. Loss: 6.910 |  Val. PPL: 1001.857\n",
            "Epoch: 07 | Time: 0m 4s\n",
            "\tTrain Loss: 7.278 | Train PPL: 1448.691\n",
            "\t Val. Loss: 6.895 |  Val. PPL: 986.883\n",
            "Epoch: 08 | Time: 0m 4s\n",
            "\tTrain Loss: 7.245 | Train PPL: 1401.259\n",
            "\t Val. Loss: 6.864 |  Val. PPL: 957.282\n",
            "Epoch: 09 | Time: 0m 4s\n",
            "\tTrain Loss: 7.214 | Train PPL: 1358.338\n",
            "\t Val. Loss: 6.844 |  Val. PPL: 938.069\n",
            "Epoch: 10 | Time: 0m 4s\n",
            "\tTrain Loss: 7.185 | Train PPL: 1318.868\n",
            "\t Val. Loss: 6.833 |  Val. PPL: 928.158\n",
            "Epoch: 11 | Time: 0m 4s\n",
            "\tTrain Loss: 7.150 | Train PPL: 1274.006\n",
            "\t Val. Loss: 6.815 |  Val. PPL: 911.566\n",
            "Epoch: 12 | Time: 0m 4s\n",
            "\tTrain Loss: 7.125 | Train PPL: 1242.370\n",
            "\t Val. Loss: 6.816 |  Val. PPL: 912.642\n",
            "Epoch: 13 | Time: 0m 4s\n",
            "\tTrain Loss: 7.085 | Train PPL: 1194.069\n",
            "\t Val. Loss: 6.821 |  Val. PPL: 916.909\n",
            "Epoch: 14 | Time: 0m 4s\n",
            "\tTrain Loss: 7.034 | Train PPL: 1134.436\n",
            "\t Val. Loss: 6.815 |  Val. PPL: 911.447\n",
            "Epoch: 15 | Time: 0m 4s\n",
            "\tTrain Loss: 6.994 | Train PPL: 1089.823\n",
            "\t Val. Loss: 6.854 |  Val. PPL: 947.344\n",
            "| Test Loss: 6.979 | Test PPL: 1074.373 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTtKZALr7epi"
      },
      "source": [
        "На игрушечных данных модель обучилась, и если обучать подольше, обещает быть адекватной.\n",
        "\n",
        "Но, кажется, я не успеваю сделать функцию с генерацией предложений, потому что ошибка не уходит никак, а уже совсем дедлайн."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxZQWtMCcSRM"
      },
      "source": [
        "\n",
        "def generate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence,str):\n",
        "        tokens = tokenizer.encode(sentence, output_type=yttm.OutputType.SUBWORD)\n",
        "    else:\n",
        "        tokens = tokenizer.encode(sentence, output_type=yttm.OutputType.SUBWORD)\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, hidden, cell)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDDQhgimvqrs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "dabfea74-7030-41af-8500-3a3f71dbde26"
      },
      "source": [
        "example_idx = 24\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['q']\n",
        "src = \" \".join(src)\n",
        "trg = vars(train_data.examples[example_idx])['ans']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "\n",
        "sent, _ = generate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = { sent }')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ▁подо ж дите ▁подо ж дите ▁еще ▁пару ▁гло т ков ▁и ▁я ▁с ▁вами\n",
            "trg = ['▁буты', 'лочку', '▁хай', 'ник', 'ена', '▁у', 'гово', 'ри', 'ла,', '▁пойдем', '▁поку', 'ри', 'м?']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-81ad921b5e6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'trg = {trg}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSRC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'predicted trg = { sent }'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-c93b2aff20ed>\u001b[0m in \u001b[0;36mgenerate_sentence\u001b[0;34m(sentence, src_field, trg_field, model, device, max_len)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mpred_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-91c762955c86>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, decoder_hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden,\n\u001b[0;32m---> 54\u001b[0;31m                                                           encoder_outputs)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mrnn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_encoder_rep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-91c762955c86>\u001b[0m in \u001b[0;36m_weighted_encoder_rep\u001b[0;34m(self, decoder_hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     29\u001b[0m                               encoder_outputs: Tensor) -> Tensor:\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-39460643b76c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, decoder_hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msrc_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mrepeated_decoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qv-z-3Hvsza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d369ed2-bca9-4505-f488-86e3eed04f6f"
      },
      "source": [
        "translation = translate_sentence('что делать', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "\n",
        "translation = translate_sentence('зачем мне это все?', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "\n",
        "translation = translate_sentence('это не нормально, памагити', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "\n",
        "translation = translate_sentence('зачем?', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "\n",
        "translation = translate_sentence('что делать, если холодно', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['▁как', '<unk>']\n",
            "predicted trg = ['▁как', '▁в']\n",
            "predicted trg = ['▁как', '▁в']\n",
            "predicted trg = ['<unk>', '<unk>']\n",
            "predicted trg = ['▁как', '<unk>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G962o6pAwBSJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}