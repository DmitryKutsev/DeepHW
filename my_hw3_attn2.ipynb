{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled44.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOgOUPlGgg0b0aFnbOgZsW8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/DeepHW/blob/master/my_hw3_attn2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2CFSkzkOu4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd4f504b-8aba-4367-bf42-25b66cd67046"
      },
      "source": [
        "!pip install youtokentome"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting youtokentome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/4a86cf99da3f680497ae132329025b291e2fda22327e8da6a9476e51acb1/youtokentome-1.0.6-cp36-cp36m-manylinux2010_x86_64.whl (1.7MB)\n",
            "\r\u001b[K     |▏                               | 10kB 11.2MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 15.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 11.7MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 7.8MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71kB 4.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81kB 5.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92kB 5.3MB/s eta 0:00:01\r\u001b[K     |██                              | 102kB 5.6MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 5.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 122kB 5.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 133kB 5.6MB/s eta 0:00:01\r\u001b[K     |██▊                             | 143kB 5.6MB/s eta 0:00:01\r\u001b[K     |██▉                             | 153kB 5.6MB/s eta 0:00:01\r\u001b[K     |███                             | 163kB 5.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 174kB 5.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 184kB 5.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 194kB 5.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 204kB 5.6MB/s eta 0:00:01\r\u001b[K     |████                            | 215kB 5.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 225kB 5.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 235kB 5.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 245kB 5.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 256kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 266kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 276kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 286kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 296kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 307kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 317kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 327kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 337kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 348kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 358kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 368kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 378kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 389kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 399kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 409kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 419kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 430kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 440kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 450kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 460kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 471kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 481kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 491kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 501kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 512kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 522kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 532kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 542kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 552kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 563kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 573kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 583kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 593kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 604kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 614kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 624kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 634kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 645kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 655kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 665kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 675kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 686kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 696kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 706kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 716kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 727kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 737kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 747kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 757kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 768kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 778kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 788kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 798kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 808kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 819kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 829kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 839kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 849kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 860kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 870kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 880kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 890kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 901kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 911kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 921kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 931kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 942kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 952kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 962kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 972kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 983kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 993kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.0MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.0MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.0MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.0MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.0MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.1MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.1MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.1MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.1MB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1MB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.1MB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.1MB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.2MB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.2MB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2MB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.2MB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2MB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.2MB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.2MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.2MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.3MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.3MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.3MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.3MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.3MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3MB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3MB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3MB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4MB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.4MB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.4MB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.4MB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4MB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.4MB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.4MB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.4MB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.4MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.5MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.5MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.5MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.5MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.5MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.5MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.5MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.5MB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5MB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6MB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.6MB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6MB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.6MB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6MB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6MB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.6MB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.6MB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.6MB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.6MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.7MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.7MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.7MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.7MB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.7MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7MB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7MB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from youtokentome) (7.1.2)\n",
            "Installing collected packages: youtokentome\n",
            "Successfully installed youtokentome-1.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwqHJV1-Epko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8fc244-d1f2-431f-bbe8-e1e5cc37f24e"
      },
      "source": [
        "!pip install alive-progress"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting alive-progress\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/46/25535783b6d88f7b85a71a4393f658baee5c5df5064c410e14058296a042/alive_progress-1.6.1-py3-none-any.whl\n",
            "Installing collected packages: alive-progress\n",
            "Successfully installed alive-progress-1.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rg43AAFBh7e"
      },
      "source": [
        "# !wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "# !dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "# !apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "# !apt-get update\n",
        "# !apt-get install cuda"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIA1x7RzBq9D"
      },
      "source": [
        "# !pip install mxnet-cu92"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmrVqnzMMxMr"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "import random\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import youtokentome as yttm"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WsCrjTDDG0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3204cfa-7b1d-4cc7-b131-138fb85ee188"
      },
      "source": [
        "print(torch.cuda.device_count())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbq8KBUcDsMc"
      },
      "source": [
        "device = torch.device('cuda:0')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB1OFN7RB-8w"
      },
      "source": [
        "# !pip install --upgrade --force-reinstall -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQsaa759SujQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e7f28a-8b2e-4ff2-899e-ce9f5e5da39d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsUhzBGgT8R-"
      },
      "source": [
        "# !unzip '/content/drive/My Drive/unsupervised.csv.zip'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqzqdz21Vh39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359e03e9-45ad-4ec1-870b-dddad9b1509a"
      },
      "source": [
        "!unzip '/content/drive/My Drive/qa_data.jsonl.zip'"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/qa_data.jsonl.zip\n",
            "  inflating: qa_data.jsonl           \n",
            "  inflating: __MACOSX/._qa_data.jsonl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpw5KDsGOrTT"
      },
      "source": [
        "# questions = pd.read_csv('unsupervised.csv')\n",
        "# questions.question = questions.question.map(lambda x: x.lower())\n",
        "\n",
        "qa_data = list()\n",
        "\n",
        "with open('qa_data.jsonl') as file_object:\n",
        "    for line in file_object:\n",
        "        qa_data.append(json.loads(line.strip()))\n",
        "file_object.close()\n",
        "qa_data = qa_data[:math.ceil(len(qa_data)*0.4)]#!!!!"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns8YADUtVxQT"
      },
      "source": [
        "with open('for_bpe.txt', 'w', encoding='utf-8') as f:\n",
        "    for que in qa_data:\n",
        "        f.write(que['question'] + '\\n')\n",
        "f.close()\n",
        "\n",
        "vocab_size = 30_000\n",
        "model_path = 'pretrained_bpe_lm.model'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy6lmKpjW8ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e350a8f4-06ab-4343-cacd-735e2e95eb97"
      },
      "source": [
        "%%time\n",
        "# обучаем\n",
        "# раскомментируйте этот код, чтобы обучить bpe\n",
        "yttm.BPE.train(data='for_bpe.txt', vocab_size=vocab_size, model=model_path)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 12.5 s, sys: 1.37 s, total: 13.8 s\n",
            "Wall time: 8.57 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<youtokentome.youtokentome.BPE at 0x7f31dc01fb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Pyz-GbXmEQ"
      },
      "source": [
        "# загружаем токенизатор\n",
        "tokenizer = yttm.BPE(model=model_path)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQPHpsjkSXEW"
      },
      "source": [
        "qa_data = qa_data[:math.ceil(len(qa_data)*0.6)]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXhx2QIskXuy"
      },
      "source": [
        "my_pairs = []\n",
        "max_length = 32\n",
        "for i in qa_data:\n",
        "  quest = i['question']\n",
        "  for resp in i['responses']:\n",
        "    pair = (quest, resp)\n",
        "    # pair.append(tok_quest, tokenizer.encode(resp, bos=True, eos=True))\n",
        "    my_pairs.append(pair)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBIho8jAixIJ"
      },
      "source": [
        "# tok_pairs = []\n",
        "# max_length = 32\n",
        "# for i in qa_data:\n",
        "  \n",
        "#   tok_quest = tokenizer.encode(i['question'], eos=True)\n",
        "#   for resp in i['responses']:\n",
        "#     pair = (tok_quest, tokenizer.encode(resp, eos=True))\n",
        "#     # pair.append(tok_quest, tokenizer.encode(resp, bos=True, eos=True))\n",
        "#     tok_pairs.append(pair)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjrqaxTfmtXh"
      },
      "source": [
        "import pandas as pd "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfb2Vx3-S1-y"
      },
      "source": [
        "my_frame = pd.DataFrame(my_pairs)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJBfciqqm06f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "64106c11-d18c-4563-ab98-75dc09287c6a"
      },
      "source": [
        "my_frame.columns = ['q', 'ans']\n",
        "my_frame = my_frame[:4000]\n",
        "my_frame"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q</th>\n",
              "      <th>ans</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>долго ли идут деньги с яндексденег на карту visa?</td>\n",
              "      <td>нет. прорыв 35 ;)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>можно ли зарегистрировать авто в другом регионе</td>\n",
              "      <td>можно на родственника из того региона.. .  а п...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>что делать если у меня очень тонкие ногти а хо...</td>\n",
              "      <td>витамины и умная эмаль (каждый день)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>что делать если у меня очень тонкие ногти а хо...</td>\n",
              "      <td>ванночки с морской солью. с вечера мажь ногти ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>что делать если у меня очень тонкие ногти а хо...</td>\n",
              "      <td>умная эмаль, витамины, йод, и поменьше крась л...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>моя дочь хочет в художественную гимнастику ей ...</td>\n",
              "      <td>нет! поздно! отдайте в бальные танцы.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>какие лучше купить витамины для 17-летней дево...</td>\n",
              "      <td>витамины фирм \"амвей\", \"арго\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>какие лучше купить витамины для 17-летней дево...</td>\n",
              "      <td>алфавит - ничего лучше раздельного приёма ещё ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>что вы хотели бы забыть ?</td>\n",
              "      <td>забыть что старость приближаетца</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>что вы хотели бы забыть ?</td>\n",
              "      <td>уже и не вспомнить-забыла!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      q                                                ans\n",
              "0     долго ли идут деньги с яндексденег на карту visa?                                  нет. прорыв 35 ;)\n",
              "1       можно ли зарегистрировать авто в другом регионе  можно на родственника из того региона.. .  а п...\n",
              "2     что делать если у меня очень тонкие ногти а хо...               витамины и умная эмаль (каждый день)\n",
              "3     что делать если у меня очень тонкие ногти а хо...  ванночки с морской солью. с вечера мажь ногти ...\n",
              "4     что делать если у меня очень тонкие ногти а хо...  умная эмаль, витамины, йод, и поменьше крась л...\n",
              "...                                                 ...                                                ...\n",
              "3995  моя дочь хочет в художественную гимнастику ей ...              нет! поздно! отдайте в бальные танцы.\n",
              "3996  какие лучше купить витамины для 17-летней дево...                      витамины фирм \"амвей\", \"арго\"\n",
              "3997  какие лучше купить витамины для 17-летней дево...  алфавит - ничего лучше раздельного приёма ещё ...\n",
              "3998                          что вы хотели бы забыть ?                   забыть что старость приближаетца\n",
              "3999                          что вы хотели бы забыть ?                         уже и не вспомнить-забыла!\n",
              "\n",
              "[4000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFIY-yxBqbGV"
      },
      "source": [
        "my_frame.to_csv('my_frame.csv', index=False)  "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbf6oJflrWb_"
      },
      "source": [
        "max_length = 20\n",
        "def tokenize(text):\n",
        "  return tokenizer.encode(text, output_type=yttm.OutputType.SUBWORD)[:max_length]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmbfDDVVrSm1"
      },
      "source": [
        "SRC = Field(tokenize=tokenize, init_token='<sos>', eos_token='<eos>')\n",
        "TRG = Field(tokenize=tokenize, init_token='<sos>', eos_token='<eos>')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT2ykmymVttb"
      },
      "source": [
        "dataset = TabularDataset(path='my_frame.csv', \n",
        "                         format='csv', \n",
        "                         fields=[ ('ans', TRG), ('q', SRC),],\n",
        "                         skip_header=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSwG260UB8Rl"
      },
      "source": [
        "train_data, valid_data, test_data = dataset.split(split_ratio=[0.7, 0.1, 0.2], \n",
        "                                            random_state=random.getstate())"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaB8jxb-VtwO"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq=2)\n",
        "TRG.build_vocab(train_data, min_freq=2)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcHhlLMVVxVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9671dc3-8c19-4166-e062-66006c78eec6"
      },
      "source": [
        "print(vars(train_data.examples[0])['ans'])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁кому', '▁сейчас', '▁жить', '▁хорошо']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cmk19Bzs-Zx"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort_key=lambda x: len(x.ans), \n",
        "     sort_within_batch=False,\n",
        "     device = device)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt5XNNdwtbl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "294fb184-be17-4883-99da-f1d078346a79"
      },
      "source": [
        "print (len(SRC.vocab), len(TRG.vocab))\n",
        "print (SRC.vocab.freqs.most_common(10))\n",
        "print (TRG.vocab.freqs.most_common(10))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4003 4689\n",
            "[('▁не', 767), ('▁и', 716), ('▁в', 566), ('.', 502), ('▁а', 389), ('▁на', 346), ('!', 277), (',', 264), ('▁что', 264), ('▁это', 253)]\n",
            "[('▁в', 631), ('▁как', 485), ('▁на', 463), ('▁что', 416), ('▁и', 389), ('▁а', 358), ('▁не', 335), ('▁с', 317), ('▁вы', 273), ('▁ли', 257)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL94XxhXtdow"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv8BdRtQtiGp"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e1n2Z9otwEH"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2l4LU5pty_E"
      },
      "source": [
        "\n",
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoYl8UaDiB2T"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UStOWuEMiB5S"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djbtvHxViB7q"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q88LUfbiKbN"
      },
      "source": [
        ""
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovYFeryZiKd-"
      },
      "source": [
        ""
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diF5dCzat10E"
      },
      "source": [
        "\n",
        "\n",
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGjqXfSliXDu"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVaBWC_rt4yw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11dc9078-59a7-4dbc-b3bb-9858c43254a4"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "model.apply(initialize_weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 7,435,089 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8wtVUIVQrnt"
      },
      "source": [
        "PAD_IDX = SRC.vocab.stoi['<pad>']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5wcy8OCt-m9"
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eckir9S6uA8f"
      },
      "source": [
        "\n",
        "\n",
        "def train(model: nn.Module,\n",
        "          iterator: torch.utils.data.DataLoader,\n",
        "          optimizer: optim.Optimizer,\n",
        "          criterion: nn.Module,\n",
        "          clip: float):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "\n",
        "        src = batch.q\n",
        "        trg = batch.ans\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kawMJSULutrA"
      },
      "source": [
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.q\n",
        "            trg = batch.ans\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMQ1hz-JuwR2"
      },
      "source": [
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9cKoYAkuyY-"
      },
      "source": [
        "import time"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "GFJX35c4Ri8Q",
        "outputId": "b322c7c8-1896-4f58-96b2-1755b756ba00"
      },
      "source": [
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut6-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-b90ca37e1847>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-36a3546cda60>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-f2328c072cab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m#trg_mask = [batch size, 1, trg len, trg len]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0menc_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m#enc_src = [batch size, src len, hid dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-303a69b27f60>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m#pos = [batch size, src len]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m#src = [batch size, src len, hid dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMzc6bIKu2fK"
      },
      "source": [
        "def translate_sentence(sentence,src_field,trg_field,model,device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    if isinstance(sentence,str):\n",
        "        tokens = tokenizer.encode(sentence, output_type=yttm.OutputType.SUBWORD)\n",
        "    else:\n",
        "        tokens = tokenizer.encode(sentence, output_type=yttm.OutputType.SUBWORD)\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        # first input to the decoder is the <sos> token\n",
        "        # output = trg[0,:]\n",
        "        # hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    #\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            print(model.decoder(trg_tensor, hidden, cell))\n",
        "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token)\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "\n",
        "    return trg_tokens[1:-1] # remove <sos> and <eos>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxZQWtMCcSRM"
      },
      "source": [
        "\n",
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence,str):\n",
        "        tokens = tokenizer.encode(sentence, output_type=yttm.OutputType.SUBWORD)\n",
        "    else:\n",
        "        tokens = tokenizer.encode(sentence, output_type=yttm.OutputType.SUBWORD)\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, hidden, cell)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDDQhgimvqrs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "616bd891-bdf3-4c79-cf30-ac427c504d09"
      },
      "source": [
        "example_idx = 24\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['q']\n",
        "src = \" \".join(src)\n",
        "trg = vars(train_data.examples[example_idx])['ans']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "\n",
        "translation, _ = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ▁голова ▁никогда ▁не ▁болит ▁от ▁любимых ▁мужчин. ▁но ▁найти ▁их ▁очень ▁сложно )\n",
            "trg = ['▁ответами', '▁навеяло', '))', '...а', '▁правда', '...что', '?))']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-f8531837d937>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'trg = {trg}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtranslation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSRC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'predicted trg = {translation}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-96ed7f3e163f>\u001b[0m in \u001b[0;36mtranslate_sentence\u001b[0;34m(sentence, src_field, trg_field, model, device, max_len)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtrg_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrg_field\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrg_field\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'src_mask'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qv-z-3Hvsza"
      },
      "source": [
        "translation = translate_sentence('что делать', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "\n",
        "translation = translate_sentence('зачем мне это все?', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "\n",
        "translation = translate_sentence('это не нормально, памагити', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "\n",
        "translation = translate_sentence('зачем?', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')\n",
        "\n",
        "translation = translate_sentence('что делать, если холодно', SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G962o6pAwBSJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}