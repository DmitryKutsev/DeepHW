{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled41.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO0YUsFmkrnuCZdWii1VMyI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/DeepHW/blob/master/hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVa_ArZt0p6i",
        "outputId": "abd8a1ee-bf54-41b0-c515-ae7eada102d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-12 16:14:36--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  15.9MB/s    in 40s     \n",
            "\n",
            "2020-10-12 16:15:17 (16.1 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLYwlK1H0TJA"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import zipfile\n",
        "\n",
        "import seaborn as sns\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DerMPE7f5Mm3",
        "outputId": "d6dd2a7c-325d-40b1-eac1-e3fc51a4290c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/master/Week%203/data.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-12 16:15:20--  https://raw.githubusercontent.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/master/Week%203/data.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10563 (10K) [text/plain]\n",
            "Saving to: ‘data.py’\n",
            "\n",
            "data.py             100%[===================>]  10.32K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-10-12 16:15:20 (10.2 MB/s) - ‘data.py’ saved [10563/10563]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcPKBhcDCVU2"
      },
      "source": [
        "!mv data.py mydata.py"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ykI-3h55GQM"
      },
      "source": [
        "from mydata import Downloader, Parser"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edch24Dm1Lz_"
      },
      "source": [
        "data_path = './data/'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFhRTbEZ0vNw"
      },
      "source": [
        "downloader = Downloader(data_path=data_path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvSwaNCn0Wbi",
        "outputId": "ff4336d2-7ebc-4af9-cb3f-b68db8dc01d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "downloader.run()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "single: 100%|██████████| 21/21 [00:30<00:00,  1.46s/it]\n",
            "multiple: 100%|██████████| 17/17 [00:35<00:00,  2.07s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIsZUJJi09CY"
      },
      "source": [
        "parser = Parser(data_path=data_path)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP0mJb-bDnTA",
        "outputId": "c52a3422-6d9d-4792-aafa-933636900990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "unlabeled, train, valid = parser.run()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading: 100%|██████████| 38/38 [02:36<00:00,  4.12s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcnwS_eFFc77",
        "outputId": "fa5d05f4-2b3e-45e9-fa6f-6bba1b0934d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "unlabeled"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>how man inches round is this?</td>\n",
              "      <td>it is 6\" same as amazon's description!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i was reading for a rotary vane pump, to not s...</td>\n",
              "      <td>if you have an inline valve to lock the vacuum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>does it come with the screen protector like th...</td>\n",
              "      <td>yes it does</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>does this product work for older women?</td>\n",
              "      <td>i am \"mature\"! and i like it. hopefully you too</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>why does the four port cost more than the five...</td>\n",
              "      <td>both the white and black color version of this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137275</th>\n",
              "      <td>will these fit a 2002 toyota celica gts?</td>\n",
              "      <td>it may take a little stretching, as it did my ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137276</th>\n",
              "      <td>does this package come with the charger for th...</td>\n",
              "      <td>thank you for your question. the baby touch bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137277</th>\n",
              "      <td>is this set the new angled bottle?</td>\n",
              "      <td>it has 2 ways to keep it straight and angled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137278</th>\n",
              "      <td>how much water does it hold? do you have to em...</td>\n",
              "      <td>it's recommended to hold 19 liters, though the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137279</th>\n",
              "      <td>iwhat about those people who have swollen ankl...</td>\n",
              "      <td>they are not tight by any means, nor do they r...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>137280 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 question                                           response\n",
              "0                           how man inches round is this?             it is 6\" same as amazon's description!\n",
              "1       i was reading for a rotary vane pump, to not s...  if you have an inline valve to lock the vacuum...\n",
              "2       does it come with the screen protector like th...                                        yes it does\n",
              "3                 does this product work for older women?    i am \"mature\"! and i like it. hopefully you too\n",
              "4       why does the four port cost more than the five...  both the white and black color version of this...\n",
              "...                                                   ...                                                ...\n",
              "137275           will these fit a 2002 toyota celica gts?  it may take a little stretching, as it did my ...\n",
              "137276  does this package come with the charger for th...  thank you for your question. the baby touch bo...\n",
              "137277                 is this set the new angled bottle?       it has 2 ways to keep it straight and angled\n",
              "137278  how much water does it hold? do you have to em...  it's recommended to hold 19 liters, though the...\n",
              "137279  iwhat about those people who have swollen ankl...  they are not tight by any means, nor do they r...\n",
              "\n",
              "[137280 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-Zdg1ePFc-h",
        "outputId": "b7fac143-7f8d-40c8-e128-b8caa14aa9e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "train"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>does it include a built-in pump?</td>\n",
              "      <td>no, mine did not come with a built in pump. it...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>does this bed plug in</td>\n",
              "      <td>this is a foam bed not an inflatable air bed.</td>\n",
              "      <td>pet supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>are these mirrors power and will they work wit...</td>\n",
              "      <td>no power,no signal, these mirrors are model sp...</td>\n",
              "      <td>automotive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>will the water freeze in below freezing temps?</td>\n",
              "      <td>i had the same question as my dogs stay outsid...</td>\n",
              "      <td>pet supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>does it have battery backup for power outages?</td>\n",
              "      <td>no battery backup</td>\n",
              "      <td>office products</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249995</th>\n",
              "      <td>do these come with bearings?</td>\n",
              "      <td>just wheels, no bearings.</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249996</th>\n",
              "      <td>does this work on a 2000chevy s-10 4.3</td>\n",
              "      <td>we can confirm the parts application with the ...</td>\n",
              "      <td>automotive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249997</th>\n",
              "      <td>can i use it for blooming gardenia? have bad s...</td>\n",
              "      <td>have quite a lot of experience with this produ...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249998</th>\n",
              "      <td>will this fit a car with a short spoiler? its ...</td>\n",
              "      <td>i'm also curious whether this bike rack will f...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249999</th>\n",
              "      <td>loved the fountain until 45 days later the pum...</td>\n",
              "      <td>i had a problem with my pump after only a coup...</td>\n",
              "      <td>pet supplies</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>250000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 question  ...             category\n",
              "0                        does it include a built-in pump?  ...  sports and outdoors\n",
              "1                                   does this bed plug in  ...         pet supplies\n",
              "2       are these mirrors power and will they work wit...  ...           automotive\n",
              "3          will the water freeze in below freezing temps?  ...         pet supplies\n",
              "4          does it have battery backup for power outages?  ...      office products\n",
              "...                                                   ...  ...                  ...\n",
              "249995                       do these come with bearings?  ...  sports and outdoors\n",
              "249996             does this work on a 2000chevy s-10 4.3  ...           automotive\n",
              "249997  can i use it for blooming gardenia? have bad s...  ...  sports and outdoors\n",
              "249998  will this fit a car with a short spoiler? its ...  ...  sports and outdoors\n",
              "249999  loved the fountain until 45 days later the pum...  ...         pet supplies\n",
              "\n",
              "[250000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiJ4PLwfFdCA",
        "outputId": "f331ce06-8d49-4c02-a9cc-4216b91739a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "valid"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>inform the size</td>\n",
              "      <td>regular size</td>\n",
              "      <td>automotive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how does it light up?</td>\n",
              "      <td>it does look like in the picture. if you take ...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>can the sneaky pete initials be removed withou...</td>\n",
              "      <td>the holster that i have is embossed.  so the s...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>for example: when this device is charging my 5...</td>\n",
              "      <td>i don't see why not, but it may slow your char...</td>\n",
              "      <td>cell phones and accessories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>does this bleeder come with a resivour cap tha...</td>\n",
              "      <td>very good cap fits all bmw's that i know of. i...</td>\n",
              "      <td>automotive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>do you ship to the u k please?</td>\n",
              "      <td>yes, when making an international order we fir...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>what size are the socks?</td>\n",
              "      <td>i think it was labeled 0-6 month, but we felt ...</td>\n",
              "      <td>baby</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>can you take off the quad rail on the pt85</td>\n",
              "      <td>yes, and you can take off the composer but the...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>are silicone bristles enough to get baby's tee...</td>\n",
              "      <td>i think it looks cute and soft and good for ba...</td>\n",
              "      <td>baby</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>does this product fold for easy travel?</td>\n",
              "      <td>no, once its set up, its bulky to move.</td>\n",
              "      <td>baby</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                question  ...                     category\n",
              "0                                        inform the size  ...                   automotive\n",
              "1                                  how does it light up?  ...          sports and outdoors\n",
              "2      can the sneaky pete initials be removed withou...  ...          sports and outdoors\n",
              "3      for example: when this device is charging my 5...  ...  cell phones and accessories\n",
              "4      does this bleeder come with a resivour cap tha...  ...                   automotive\n",
              "...                                                  ...  ...                          ...\n",
              "49995                     do you ship to the u k please?  ...          sports and outdoors\n",
              "49996                           what size are the socks?  ...                         baby\n",
              "49997         can you take off the quad rail on the pt85  ...          sports and outdoors\n",
              "49998  are silicone bristles enough to get baby's tee...  ...                         baby\n",
              "49999            does this product fold for easy travel?  ...                         baby\n",
              "\n",
              "[50000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV5meMEUDpGn",
        "outputId": "03a8f634-a346-4660-a639-4c4db465ecd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# проверим, что в трейне и валидации одинаковые категории\n",
        "set(train.category.unique().tolist()) == set(valid.category.unique().tolist())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eQK8kIxFPwi",
        "outputId": "979e442c-0442-4647-87a4-99064b633e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train.category.unique()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['sports and outdoors', 'pet supplies', 'automotive',\n",
              "       'office products', 'cell phones and accessories', 'beauty', 'baby',\n",
              "       'grocery and gourmet food'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZooQ3GPrFSyC"
      },
      "source": [
        "unique_categories = set(train.category.unique().tolist() + valid.category.unique().tolist())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwpJxzo7GQRW"
      },
      "source": [
        "category2index = {category: index for index, category in enumerate(unique_categories)}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X7NcoIKGSLP",
        "outputId": "e686cad6-1e2d-43c0-9244-b1fb0847e387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "category2index"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'automotive': 2,\n",
              " 'baby': 0,\n",
              " 'beauty': 5,\n",
              " 'cell phones and accessories': 6,\n",
              " 'grocery and gourmet food': 7,\n",
              " 'office products': 4,\n",
              " 'pet supplies': 3,\n",
              " 'sports and outdoors': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UlYn4_WGUkj"
      },
      "source": [
        "train['target'] = train.category.map(category2index)\n",
        "valid['target'] = valid.category.map(category2index)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fesvuXoTH2ig"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANqNmiwnH44r"
      },
      "source": [
        "# игрушечный датасет\n",
        "# 121535 примера, 4 фичи, 3 класса\n",
        "some_data_x = np.random.rand(121535, 4)\n",
        "some_data_y = np.random.randint(3, size=(121535,))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMXFfh9lI3Ky",
        "outputId": "5cb4c7b3-3a7f-4a53-c6bf-299435f7a89d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "\n",
        "# просто рандомные цифры\n",
        "some_data_x[:10]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.14281792, 0.96065793, 0.35854546, 0.46609858],\n",
              "       [0.78829209, 0.99061179, 0.93469212, 0.63162634],\n",
              "       [0.56110753, 0.32590169, 0.29516193, 0.66546604],\n",
              "       [0.05460179, 0.56229444, 0.25854876, 0.74157347],\n",
              "       [0.78322014, 0.71402004, 0.82926823, 0.02103047],\n",
              "       [0.03088728, 0.16838446, 0.05238811, 0.77739535],\n",
              "       [0.92362605, 0.58298071, 0.96170413, 0.04724381],\n",
              "       [0.1156664 , 0.94897289, 0.72421643, 0.77475617],\n",
              "       [0.1441345 , 0.66750075, 0.14935046, 0.55240946],\n",
              "       [0.13499113, 0.04023578, 0.97030316, 0.74390511]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wVluH7IKF__",
        "outputId": "7facf3fe-30f4-44ce-af20-1d8bdd2868d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "some_data_y"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 2, ..., 2, 0, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHC9j0ecKLi7"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "for i_batch in range(math.ceil(some_data_x.shape[0] / batch_size)):\n",
        "    \n",
        "    x_batch = some_data_x[i_batch * batch_size:(i_batch + 1) * batch_size]\n",
        "    y_batch = some_data_y[i_batch * batch_size:(i_batch + 1) * batch_size]\n",
        "    \n",
        "    x_batch = torch.tensor(x_batch)\n",
        "    y_batch = torch.tensor(y_batch)\n",
        "    \n",
        "    break"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFUbych6KTzD",
        "outputId": "0fdf4387-17b5-413f-e541-242005fcdb94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "x_batch"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1428, 0.9607, 0.3585, 0.4661],\n",
              "        [0.7883, 0.9906, 0.9347, 0.6316],\n",
              "        [0.5611, 0.3259, 0.2952, 0.6655],\n",
              "        [0.0546, 0.5623, 0.2585, 0.7416],\n",
              "        [0.7832, 0.7140, 0.8293, 0.0210],\n",
              "        [0.0309, 0.1684, 0.0524, 0.7774],\n",
              "        [0.9236, 0.5830, 0.9617, 0.0472],\n",
              "        [0.1157, 0.9490, 0.7242, 0.7748],\n",
              "        [0.1441, 0.6675, 0.1494, 0.5524],\n",
              "        [0.1350, 0.0402, 0.9703, 0.7439],\n",
              "        [0.4586, 0.4394, 0.7310, 0.3827],\n",
              "        [0.3263, 0.9888, 0.2229, 0.6774],\n",
              "        [0.8750, 0.1231, 0.9995, 0.9140],\n",
              "        [0.4950, 0.2194, 0.7018, 0.8395],\n",
              "        [0.2697, 0.0832, 0.7929, 0.4384],\n",
              "        [0.4111, 0.6586, 0.7293, 0.5973]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UnWnWn_KWf0",
        "outputId": "b3dc53d4-8f82-4924-a69e-bf6f2b8f2547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_batch.shape, y_batch.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 4]), torch.Size([16]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU_qiEgSKYDC"
      },
      "source": [
        "class ToyDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data_x, data_y):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.data_x = data_x\n",
        "        self.data_y = data_y\n",
        "        \n",
        "    def __len__(self):\n",
        "        \n",
        "        # нужно обязательно определить эту функцию\n",
        "        # должна возвращать размер датасета\n",
        "        # нужен для DataLoader, чтобы семплировать батчи\n",
        "        \n",
        "        return len(self.data_x)\n",
        "    \n",
        "    @staticmethod\n",
        "    def pow_features(x, n=2):\n",
        "        \n",
        "        return x ** n\n",
        "    \n",
        "    @staticmethod\n",
        "    def log_features(x):\n",
        "        \n",
        "        return np.log(x)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        # еще нужно определить этот метод\n",
        "        # то есть как мы будем доставать наши данные по индексу\n",
        "        \n",
        "        x = self.data_x[idx]\n",
        "        \n",
        "        # внутри датасета мы можем делать все что угодно с нашими данными\n",
        "        # например выше определим функции, которые добавляют степенные фичи\n",
        "        x_p_2 = self.pow_features(x, n=2)\n",
        "        x_p_3 = self.pow_features(x, n=3)\n",
        "        # и еще возьмем логарифмические фичи\n",
        "        x_log = self.log_features(x)\n",
        "        \n",
        "        # сконкатенируем наши фичи\n",
        "        x = np.concatenate([x, x_p_2, x_p_3, x_log])\n",
        "        \n",
        "        y = self.data_y[idx]\n",
        "        \n",
        "        return x, y"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45_ikW0r0Ndj"
      },
      "source": [
        "toy_dataset = ToyDataset(some_data_x, some_data_y)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay3RCo1lvuRw"
      },
      "source": [
        "toy_loader = DataLoader(dataset=toy_dataset, batch_size=128)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryJ6LL9uvuPQ"
      },
      "source": [
        "for x, y in toy_loader:\n",
        "    break"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXNIRm5xvuM0",
        "outputId": "ecf1fbdd-cb46-47dc-acbc-e616f7ebdcb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# сделаем небольшую модель и посчитаем лосс\n",
        "\n",
        "model = torch.nn.Sequential(torch.nn.Linear(16, 8),\n",
        "                            torch.nn.ReLU(),\n",
        "                            torch.nn.Linear(8, 4),\n",
        "                            torch.nn.ReLU(),\n",
        "                            torch.nn.Linear(4, 3))\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    prediction = model(x.float())\n",
        "\n",
        "    loss = criterion(prediction, y)\n",
        "    \n",
        "loss.item()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0921432971954346"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f36PQFvfvuKq"
      },
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, texts, targets):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.texts = texts\n",
        "        self.targets = targets\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        text = self.texts[index]\n",
        "        target = self.targets[index]\n",
        "        \n",
        "        return text, target"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1N9Bzr3wQZi"
      },
      "source": [
        "\n",
        "# подготовим данные\n",
        "train_x = list(train.question)\n",
        "train_y = list(train.target)\n",
        "\n",
        "valid_x = list(valid.question)\n",
        "valid_y = list(valid.target)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZiJzdUewQXI"
      },
      "source": [
        "train_dataset = TextClassificationDataset(texts=list(train.question), targets=list(train.target))"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2tUleFVwQUy"
      },
      "source": [
        "text, target = train_dataset[0]"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvGWCuaIv2_M"
      },
      "source": [
        "def load_embeddings(zip_path, filename, pad_token='PAD', max_words=100_000, verbose=True):\n",
        "    \n",
        "    vocab = dict()\n",
        "    embeddings = list()\n",
        "\n",
        "    with zipfile.ZipFile(zip_path) as zipped_file:\n",
        "        with zipped_file.open(filename) as file_object:\n",
        "\n",
        "            vocab_size, embedding_dim = file_object.readline().decode('utf-8').strip().split()\n",
        "\n",
        "            vocab_size = int(vocab_size)\n",
        "            embedding_dim = int(embedding_dim)\n",
        "            \n",
        "            # в файле 1 000 000 слов с векторами, давайте ограничим для простоты этот словарь\n",
        "            max_words = vocab_size if max_words <= 0 else max_words\n",
        "            \n",
        "            # добавим пад токен и эмбеддинг в нашу матрицу эмбеддингов и словарь\n",
        "            vocab[pad_token] = len(vocab)\n",
        "            embeddings.append(np.zeros(embedding_dim))\n",
        "\n",
        "            progress_bar = tqdm(total=max_words, disable=not verbose)\n",
        "\n",
        "            for line in file_object:\n",
        "                parts = line.decode('utf-8').strip().split()\n",
        "\n",
        "                token = ' '.join(parts[:-embedding_dim]).lower()\n",
        "                \n",
        "                if token in vocab:\n",
        "                    continue\n",
        "                \n",
        "                word_vector = np.array(list(map(float, parts[-embedding_dim:])))\n",
        "\n",
        "                vocab[token] = len(vocab)\n",
        "                embeddings.append(word_vector)\n",
        "\n",
        "                progress_bar.update()\n",
        "                \n",
        "                if len(vocab) == max_words:\n",
        "                    break\n",
        "\n",
        "            progress_bar.close()\n",
        "\n",
        "    embeddings = np.stack(embeddings)\n",
        "    \n",
        "    return vocab, embeddings"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jassF1n_v3Fx",
        "outputId": "746b47b3-0494-4c90-9517-73afeff2e91d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab, embeddings = load_embeddings('./wiki-news-300d-1M.vec.zip', 'wiki-news-300d-1M.vec', max_words=100_000)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 99999/100000 [00:12<00:00, 8278.11it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmxVKTcKweRc"
      },
      "source": [
        "index2token = {index: token for token, index in vocab.items()}"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1TBM9chwePH"
      },
      "source": [
        "emb_norms = np.linalg.norm(embeddings, axis=1)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8W9TN7rweMh"
      },
      "source": [
        "def get_k_nearest_neighbors(word, embeddings, emb_norms, vocab, index2token, k=5):\n",
        "    \n",
        "    if word not in vocab:\n",
        "        print('Not in vocab')\n",
        "        return\n",
        "    \n",
        "    word_index = vocab[word]\n",
        "\n",
        "    word_vector = embeddings[word_index]\n",
        "    word_vector = np.expand_dims(word_vector, 0)\n",
        "\n",
        "    scores = (word_vector @ embeddings.T)[0]\n",
        "    \n",
        "    # переводим в косинусы, поделив на нормы векторов\n",
        "    # эпсилон 1e-6 для того, чтобы не делить на 0\n",
        "    scores = scores / (emb_norms + 1e-6) / emb_norms[word_index]\n",
        "    \n",
        "    # 1:k+1 потому что первый вариант это само слово\n",
        "    for idx in scores.argsort()[::-1][1:k+1]:\n",
        "        print(f'Слово {index2token[idx]} близко на {scores[idx]:.2f} к слову {word}')"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSYaRdzxwCHg",
        "outputId": "536fcb9b-6e7e-40f3-dc75-8a9cab5f3b8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "total_n_words = 0\n",
        "unknown_words = list()\n",
        "\n",
        "for sample in tqdm(train_x):\n",
        "    # токенизация\n",
        "    tokens = wordpunct_tokenize(sample)\n",
        "    \n",
        "    for tok in tokens:\n",
        "        # проверяем есть ли токен в нашем словаре\n",
        "        if tok not in vocab:\n",
        "            unknown_words.append(tok)\n",
        "            \n",
        "        total_n_words += 1\n",
        "        \n",
        "print(f'Мы не знаем {len(unknown_words)} слов из {total_n_words} слов в датасете')\n",
        "print(f'Что составляет {len(unknown_words) * 100 / total_n_words:.2f}% датасета')\n",
        "print()\n",
        "print(f'Уникальных неизвестных слов: {len(set(unknown_words))}')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250000/250000 [00:03<00:00, 82472.27it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Мы не знаем 110907 слов из 4203856 слов в датасете\n",
            "Что составляет 2.64% датасета\n",
            "\n",
            "Уникальных неизвестных слов: 36053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWOFRoBlwCOA"
      },
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, texts, targets, vocab):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.texts = texts\n",
        "        self.targets = targets\n",
        "        self.vocab = vocab\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def tokenization(self, text):\n",
        "        \n",
        "        tokens = wordpunct_tokenize(text)\n",
        "        \n",
        "        token_indices = [self.vocab[tok] for tok in tokens if tok in self.vocab]\n",
        "        \n",
        "        return token_indices\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        text = self.texts[index]        \n",
        "        target = self.targets[index]\n",
        "        \n",
        "        tokenized_text = self.tokenization(text)\n",
        "        \n",
        "        # переведем наши индексы токенов в торчовый тензор\n",
        "        # таргет переведется самостоятельно\n",
        "        tokenized_text = torch.tensor(tokenized_text)\n",
        "        \n",
        "        return tokenized_text, target"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1GCemE1wCLc"
      },
      "source": [
        "train_dataset = TextClassificationDataset(texts=train_x, targets=train_y, vocab=vocab)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXAaFbq-w7w8"
      },
      "source": [
        "x, y = train_dataset[5]"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtaNmLABw8JB"
      },
      "source": [
        "# [index2token[idx.item()] for idx in x]"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s8zGSC6w8Xw",
        "outputId": "9f0ca062-3647-4975-a184-193c2481f878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_lengths = [len(wordpunct_tokenize(sample)) for sample in tqdm(train_x)]"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250000/250000 [00:01<00:00, 193995.94it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc43WB7Dw7um"
      },
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, texts, targets, vocab, pad_index=0, max_length=32):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.texts = texts\n",
        "        self.targets = targets\n",
        "        self.vocab = vocab\n",
        "        \n",
        "        self.pad_index = pad_index\n",
        "        self.max_length = max_length\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def tokenization(self, text):\n",
        "        \n",
        "        tokens = wordpunct_tokenize(text)\n",
        "        \n",
        "        token_indices = [self.vocab[tok] for tok in tokens if tok in self.vocab]\n",
        "        \n",
        "        return token_indices\n",
        "    \n",
        "    def padding(self, tokenized_text):\n",
        "        \n",
        "        tokenized_text = tokenized_text[:self.max_length]\n",
        "        \n",
        "        tokenized_text += [self.pad_index] * (self.max_length - len(tokenized_text))\n",
        "        \n",
        "        return tokenized_text\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        text = self.texts[index]        \n",
        "        target = self.targets[index]\n",
        "        \n",
        "        tokenized_text = self.tokenization(text)\n",
        "        tokenized_text = self.padding(tokenized_text)\n",
        "        \n",
        "        tokenized_text = torch.tensor(tokenized_text)\n",
        "        \n",
        "        return tokenized_text, target"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw5rujbUw7sG"
      },
      "source": [
        "train_dataset = TextClassificationDataset(texts=train_x, targets=train_y, vocab=vocab)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-gw8zSfw7pv"
      },
      "source": [
        "x, y = train_dataset[0]"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz13zTh4w7me"
      },
      "source": [
        "train_dataset = TextClassificationDataset(texts=train_x, targets=train_y, vocab=vocab)\n",
        "valid_dataset = TextClassificationDataset(texts=valid_x, targets=valid_y, vocab=vocab)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=128)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L54QjEz8zt1q",
        "outputId": "3c969cb2-5dee-4835-ed25-3c77df1c7c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "\n",
        "for x, y in train_loader:\n",
        "    print(x, y)\n",
        "    break"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 218,   20,  264,  ...,    0,    0,    0],\n",
            "        [ 218,   29, 2591,  ...,    0,    0,    0],\n",
            "        [  32,  130, 7624,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [  28,  231,    6,  ...,    0,    0,    0],\n",
            "        [  29, 1607, 1101,  ...,    0,    0,    0],\n",
            "        [  97,   30,  231,  ...,  168,    5,  730]]) tensor([1, 3, 2, 3, 4, 1, 6, 1, 6, 1, 2, 6, 3, 5, 6, 2, 1, 2, 2, 0, 4, 2, 5, 1,\n",
            "        4, 6, 7, 1, 3, 2, 1, 6, 2, 1, 0, 6, 6, 7, 2, 2, 0, 5, 5, 3, 6, 3, 2, 1,\n",
            "        1, 1, 1, 2, 1, 3, 1, 1, 2, 4, 4, 6, 4, 2, 1, 6, 5, 4, 6, 6, 4, 0, 2, 0,\n",
            "        5, 2, 2, 3, 2, 2, 1, 1, 5, 1, 6, 5, 6, 1, 5, 6, 4, 3, 3, 2, 2, 0, 5, 6,\n",
            "        3, 3, 4, 4, 1, 1, 6, 2, 0, 3, 4, 3, 2, 1, 1, 2, 5, 4, 1, 5, 6, 4, 2, 1,\n",
            "        2, 2, 1, 3, 5, 1, 6, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FVu0LeFzy0r",
        "outputId": "a7537d72-08c4-48dc-e52f-36746dc51bc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "list(train_loader)[0]"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 218,   20,  264,  ...,    0,    0,    0],\n",
              "         [ 218,   29, 2591,  ...,    0,    0,    0],\n",
              "         [  32,  130, 7624,  ...,    0,    0,    0],\n",
              "         ...,\n",
              "         [  28,  231,    6,  ...,    0,    0,    0],\n",
              "         [  29, 1607, 1101,  ...,    0,    0,    0],\n",
              "         [  97,   30,  231,  ...,  168,    5,  730]]),\n",
              " tensor([1, 3, 2, 3, 4, 1, 6, 1, 6, 1, 2, 6, 3, 5, 6, 2, 1, 2, 2, 0, 4, 2, 5, 1,\n",
              "         4, 6, 7, 1, 3, 2, 1, 6, 2, 1, 0, 6, 6, 7, 2, 2, 0, 5, 5, 3, 6, 3, 2, 1,\n",
              "         1, 1, 1, 2, 1, 3, 1, 1, 2, 4, 4, 6, 4, 2, 1, 6, 5, 4, 6, 6, 4, 0, 2, 0,\n",
              "         5, 2, 2, 3, 2, 2, 1, 1, 5, 1, 6, 5, 6, 1, 5, 6, 4, 3, 3, 2, 2, 0, 5, 6,\n",
              "         3, 3, 4, 4, 1, 1, 6, 2, 0, 3, 4, 3, 2, 1, 1, 2, 5, 4, 1, 5, 6, 4, 2, 1,\n",
              "         2, 2, 1, 3, 5, 1, 6, 5])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJCzXfMvvuH-"
      },
      "source": [
        "embedding_layer = nn.Embedding(num_embeddings=len(vocab), \n",
        "                               embedding_dim=embeddings.shape[-1],\n",
        "                               padding_idx=0)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaYtPGVdxncn",
        "outputId": "f70b9703-e01c-4945-ccee-c00732ff21ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "embeddings = torch.tensor(embeddings).float()\n",
        "embedding_layer = nn.Embedding.from_pretrained(embeddings, padding_idx=0)\n",
        "x_embed = embedding_layer(x)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPkF6VsGxn6-"
      },
      "source": [
        "lstm = nn.LSTM(input_size=300, hidden_size=128, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFt1fRA3xnZy"
      },
      "source": [
        "x_lstm, _ = lstm(x_embed)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNQVaiQXxu6r",
        "outputId": "1e79e8fa-f7cd-4bf0-97f9-22f4c88b3f65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_lstm.mean(dim=1).shape"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3VqEOn3xu4L"
      },
      "source": [
        "class DeepAverageNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self, embeddings, linear_1_size, linear_2_size, n_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding_layer = nn.Embedding.from_pretrained(embeddings, padding_idx=0)\n",
        "        \n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=embeddings.shape[-1])\n",
        "        \n",
        "        self.linear_1 = nn.Linear(in_features=embeddings.shape[-1], out_features=linear_1_size)\n",
        "        self.linear_2 = nn.Linear(in_features=linear_1_size, out_features=linear_2_size)\n",
        "        self.linear_3 = nn.Linear(in_features=linear_2_size, out_features=n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # переводим индексы слов в эмбеддинги этих слов\n",
        "        # (batch_size, sequence_length) -> (batch_size, sequence_length, embedding_dim)\n",
        "        x = self.embedding_layer(x)\n",
        "        \n",
        "        # агрегируем наши эмбеддинги по размерности время\n",
        "        # (batch_size, sequence_length, embedding_dim) -> (batch_size, embedding_dim)\n",
        "        x = x.sum(dim=1)\n",
        "        \n",
        "        # делаем нормирование\n",
        "        # (batch_size, embedding_dim) -> (batch_size, embedding_dim)\n",
        "        x = self.batch_norm(x)\n",
        "        \n",
        "        # прогоняем через первый линейный слой\n",
        "        # (batch_size, embedding_dim) -> (batch_size, linear_1_size)\n",
        "        x = self.linear_1(x)\n",
        "        \n",
        "        # применяем нелинейность\n",
        "        # (batch_size, linear_1_size) -> (batch_size, linear_1_size)\n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        # прогоняем через второй линейный слой\n",
        "        # (batch_size, linear_1_size) -> (batch_size, linear_2_size)\n",
        "        x = self.linear_2(x)\n",
        "        \n",
        "        # применяем нелинейность\n",
        "        # (batch_size, linear_2_size) -> (batch_size, linear_2_size)\n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        # переводим с помощью линейного преобразования в количество классов\n",
        "        # (batch_size, linear_2_size) -> (batch_size, n_classes)\n",
        "        x = self.linear_3(x)\n",
        "        \n",
        "        ## по идеи здесь должен был быть софтмакс\n",
        "        ## но мы будем использовать лосс nn.CrossEntropyLoss()\n",
        "        ## в его документации написано\n",
        "        ## This criterion combines :func:`nn.LogSoftmax` and :func:`nn.NLLLoss` in one single class.\n",
        "        ## это некоторая оптимизация, которая включает в себя сразу и софтмакс и сам negative log likelihood лосс\n",
        "        ## так как у нас в лоссе есть софтмакс, то мы не будем применять его в сетке\n",
        "        ## на этапе предсказания (а не обучения) мы будем отдельно делать софтмакс для получения распределения классов\n",
        "        ## \n",
        "        ## (batch_size, n_classes) -> (batch_size, n_classes)\n",
        "        # x = torch.softmax(x, dim=-1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnqf_o_Rxu1Y"
      },
      "source": [
        "model = DeepAverageNetwork(embeddings=embeddings,\n",
        "                           linear_1_size=256, \n",
        "                           linear_2_size=128, \n",
        "                           n_classes=len(category2index))"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK1lSFxDxnXV"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTcB503qxnVA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c7j38kOxnR2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WicD52dbluUP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}